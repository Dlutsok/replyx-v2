from fastapi import APIRouter, Depends, HTTPException, Query, UploadFile, File
from sqlalchemy.orm import Session, joinedload, selectinload
from sqlalchemy import func
from typing import List as TypingList, Optional
from datetime import datetime, timedelta
import json
import os
import logging
import jwt

from database import SessionLocal, models, schemas, crud, auth
from database.connection import get_db
from fastapi import BackgroundTasks
from pydantic import BaseModel
from validators.file_validator import FileValidator
from ai.ai_token_manager import ai_token_manager

logger = logging.getLogger(__name__)

router = APIRouter()

# get_db –∏–º–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç—Å—è –∏–∑ database.connection

# Helper functions to avoid circular imports
def invalidate_assistant_cache(assistant_id: int):
    """Wrapper –¥–ª—è –∏–Ω–≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∫—ç—à–∞ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞"""
    try:
        from cache.redis_cache import chatai_cache
        chatai_cache.invalidate_assistant_cache(assistant_id)
    except ImportError:
        pass

def hot_reload_assistant_bots(assistant_id: int, db: Session):
    """–ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ñ—É–Ω–∫—Ü–∏—é —Ç–æ–ª—å–∫–æ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ"""
    try:
        from main import hot_reload_assistant_bots as _hot_reload
        return _hot_reload(assistant_id, db)
    except ImportError:
        pass

def reload_assistant_bots(assistant_id: int, db: Session):
    """–ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ñ—É–Ω–∫—Ü–∏—é —Ç–æ–ª—å–∫–æ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ"""
    try:
        from main import reload_assistant_bots as _reload
        return _reload(assistant_id, db)
    except ImportError:
        pass

# --- Assistant CRUD ---

@router.get("/assistants/{assistant_id}", response_model=schemas.AssistantRead)
def get_assistant(assistant_id: int, db: Session = Depends(get_db), current_user: models.User = Depends(auth.get_current_user)):
    """
    –ü–æ–ª—É—á–∏—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –ø–æ ID
    """
    effective_user_id = auth.get_effective_user_id(current_user, db)
    assistant = crud.get_assistant(db, assistant_id)
    
    if not assistant or assistant.user_id != effective_user_id:
        raise HTTPException(status_code=404, detail="Assistant not found")
    
    return assistant

@router.get("/assistants", response_model=TypingList[schemas.AssistantRead])
def get_my_assistants(db: Session = Depends(get_db), current_user: models.User = Depends(auth.get_current_user)):
    """
    Optimized assistants endpoint - uses eager loading to avoid N+1 queries
    """
    effective_user_id = auth.get_effective_user_id(current_user, db)
    logger.debug(f"[API] Fetching assistants for user {effective_user_id} (effective from {current_user.id})")
    
    # Using optimized CRUD function that includes eager loading
    assistants = crud.get_assistants(db, effective_user_id)
    
    logger.debug(f"[API] Retrieved {len(assistants)} assistants with optimized query")
    return assistants

@router.post("/assistants", response_model=schemas.AssistantRead)
def create_my_assistant(data: schemas.AssistantCreate, db: Session = Depends(get_db), current_user: models.User = Depends(auth.get_current_user)):
    assistant = crud.create_assistant(db, current_user.id, data)
    
    # –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∂–∞–µ–º —Ç–æ–ª—å–∫–æ –±–æ—Ç—ã –Ω–æ–≤–æ–≥–æ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ (–µ—Å–ª–∏ –µ—Å—Ç—å)
    reload_assistant_bots(assistant.id, db)
    
    return assistant

@router.patch("/assistants/{assistant_id}")
def update_my_assistant(assistant_id: int, data: dict, db: Session = Depends(get_db), current_user: models.User = Depends(auth.get_current_user)):
    from validators.input_validator import validate_assistant_data, ValidationError, create_validation_error_response
    
    try:
        print(f"[UPDATE_ASSISTANT] –ü–æ–ª—É—á–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ: {data}")
        print(f"[UPDATE_ASSISTANT] –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: {current_user.id}")
        print(f"[UPDATE_ASSISTANT] Assistant ID: {assistant_id}")
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        try:
            # –î–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è name –Ω–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ
            temp_data = data.copy()
            if 'name' not in temp_data:
                temp_data['name'] = 'temp'  # –≤—Ä–µ–º–µ–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
            validated_data = validate_assistant_data(temp_data)
            if 'name' not in data and 'name' in validated_data:
                del validated_data['name']  # —É–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
        except ValidationError as e:
            # –ï—Å–ª–∏ –ø—Ä–∏–ª–µ—Ç–µ–ª –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–π name ‚Äî –ø—Ä–æ–ø—É—Å—Ç–∏–º —Ç–æ–ª—å–∫–æ name, –æ—Å—Ç–∞–ª—å–Ω—ã–µ –ø–æ–ª—è —Å–æ—Ö—Ä–∞–Ω–∏–º
            if getattr(e, 'field', None) == 'name':
                safe_data = data.copy()
                safe_data.pop('name', None)
                safe_tmp = safe_data.copy()
                safe_tmp['name'] = 'temp'
                validated_data = validate_assistant_data(safe_tmp)
                if 'name' in validated_data:
                    del validated_data['name']
                logger.warning(f"[UPDATE_ASSISTANT] –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –Ω–µ–≤–∞–ª–∏–¥–Ω–æ–µ –∏–º—è: {e}")
            else:
                raise create_validation_error_response(e)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∏—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
        assistant = crud.get_assistant(db, assistant_id)
        if not assistant:
            print(f"[UPDATE_ASSISTANT] –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç {assistant_id} –Ω–µ –Ω–∞–π–¥–µ–Ω")
            raise HTTPException(status_code=404, detail="Assistant not found")
        if assistant.user_id != current_user.id:
            print(f"[UPDATE_ASSISTANT] –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç {assistant_id} –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∏—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é {assistant.user_id}, –∞ –Ω–µ {current_user.id}")
            raise HTTPException(status_code=404, detail="Assistant not found")
        
        print(f"[UPDATE_ASSISTANT] –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç –Ω–∞–π–¥–µ–Ω: {assistant.name}")
        
        # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç AssistantUpdate —Ç–æ–ª—å–∫–æ —Å –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã–º–∏ –ø–æ–ª—è–º–∏
        filtered_data = {k: v for k, v in validated_data.items() if k in ['name', 'ai_model', 'system_prompt', 'is_active']}
        
        # –î–æ–±–∞–≤–ª—è–µ–º allowed_domains –µ—Å–ª–∏ –æ–Ω –±—ã–ª –ø–µ—Ä–µ–¥–∞–Ω –Ω–∞–ø—Ä—è–º—É—é –≤ data (–æ–±—Ö–æ–¥–∏–º –≤–∞–ª–∏–¥–∞—Ü–∏—é)
        if 'allowed_domains' in data:
            filtered_data['allowed_domains'] = data['allowed_domains']
            
        # –ë–µ–∑–æ–ø–∞—Å–Ω–æ –¥–æ–±–∞–≤–ª—è–µ–º –ø–æ–ª—è –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏–∏ –≤–∏–¥–∂–µ—Ç–∞
        widget_fields = ['operator_name', 'business_name', 'avatar_url', 'widget_theme', 'widget_settings']
        for field in widget_fields:
            if field in data:
                filtered_data[field] = data[field]
        print(f"[UPDATE_ASSISTANT] –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: {filtered_data}")
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –Ω–∞–ø—Ä—è–º—É—é, –±–µ–∑ —Å–æ–∑–¥–∞–Ω–∏—è —Å—Ö–µ–º—ã
        for field, value in filtered_data.items():
            if hasattr(assistant, field):
                setattr(assistant, field, value)
                print(f"[UPDATE_ASSISTANT] –û–±–Ω–æ–≤–ª–µ–Ω–æ –ø–æ–ª–µ {field}: {value}")
        
        assistant.updated_at = datetime.utcnow()
        db.commit()
        db.refresh(assistant)
        updated_assistant = assistant
        print(f"[UPDATE_ASSISTANT] –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç –æ–±–Ω–æ–≤–ª–µ–Ω: {updated_assistant.name}")
        
        # üî• –ò–Ω–≤–∞–ª–∏–¥–∏—Ä—É–µ–º –∫—ç—à –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞
        invalidate_assistant_cache(assistant_id)
        print(f"[UPDATE_ASSISTANT] –ö—ç—à –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ {assistant_id} –∏–Ω–≤–∞–ª–∏–¥–∏—Ä–æ–≤–∞–Ω")
        
        # üî• –ë–∞–º–ø –≤–µ—Ä—Å–∏–∏ –∑–Ω–∞–Ω–∏–π, —á—Ç–æ–±—ã –∫—ç—à –æ—Ç–≤–µ—Ç–æ–≤ –ø–µ—Ä–µ—Å—Ç–∞–ª —Å–æ–≤–ø–∞–¥–∞—Ç—å –ø—Ä–∏ —Å–º–µ–Ω–µ system_prompt/ai_model
        try:
            from services.embeddings_service import embeddings_service
            embeddings_service.increment_knowledge_version(assistant_id, db)
        except Exception as _e:
            logger.warning(f"[UPDATE_ASSISTANT] Failed to bump knowledge version: {_e}")

        # üî• –ì–û–†–Ø–ß–ê–Ø –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∞ –Ω–∞—Å—Ç—Ä–æ–µ–∫ –≤–º–µ—Å—Ç–æ –ø–æ–ª–Ω–æ–≥–æ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞
        hot_reload_assistant_bots(assistant_id, db)
        
        return {
            "id": updated_assistant.id,
            "name": updated_assistant.name,
            "ai_model": updated_assistant.ai_model,
            "system_prompt": updated_assistant.system_prompt,
            "is_active": updated_assistant.is_active,
            "website_integration_enabled": updated_assistant.website_integration_enabled,
            "allowed_domains": updated_assistant.allowed_domains,
            "user_id": updated_assistant.user_id,
            # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ–ª—è –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏–∏ –≤–∏–¥–∂–µ—Ç–∞
            "operator_name": getattr(updated_assistant, 'operator_name', '–ü–æ–¥–¥–µ—Ä–∂–∫–∞'),
            "business_name": getattr(updated_assistant, 'business_name', '–ù–∞—à–∞ –∫–æ–º–ø–∞–Ω–∏—è'),
            "avatar_url": getattr(updated_assistant, 'avatar_url', None),
            "widget_theme": getattr(updated_assistant, 'widget_theme', 'blue'),
            "widget_settings": getattr(updated_assistant, 'widget_settings', {}),
            "created_at": updated_assistant.created_at.isoformat() if updated_assistant.created_at else None,
            "updated_at": updated_assistant.updated_at.isoformat() if updated_assistant.updated_at else None
        }
    except Exception as e:
        print(f"[UPDATE_ASSISTANT] –û—à–∏–±–∫–∞: {e}")
        import traceback
        print(f"[UPDATE_ASSISTANT] Traceback: {traceback.format_exc()}")
        raise

@router.delete("/assistants/{assistant_id}")
def delete_my_assistant(assistant_id: int, db: Session = Depends(get_db), current_user: models.User = Depends(auth.get_current_user)):
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —è–≤–ª—è–µ—Ç—Å—è –≤–ª–∞–¥–µ–ª—å—Ü–µ–º –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏
    if not auth.is_organization_owner(current_user, db):
        raise HTTPException(
            status_code=403, 
            detail="–¢–æ–ª—å–∫–æ –≤–ª–∞–¥–µ–ª—å—Ü—ã –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ –º–æ–≥—É—Ç —É–¥–∞–ª—è—Ç—å –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–æ–≤"
        )
    
    effective_user_id = auth.get_effective_user_id(current_user, db)
    assistant = crud.get_assistant(db, assistant_id)
    if not assistant or assistant.user_id != effective_user_id:
        raise HTTPException(status_code=404, detail="Assistant not found")
    
    # –ù–∞–π—Ç–∏ id –≤—Å–µ—Ö –±–æ—Ç-–∏–Ω—Å—Ç–∞–Ω—Å–æ–≤ —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å —ç—Ç–∏–º –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–æ–º (–±–µ–∑ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–æ–ª–æ–Ω–æ–∫)
    bot_ids = [row[0] for row in db.query(models.BotInstance.id).filter(
        models.BotInstance.assistant_id == assistant_id,
        models.BotInstance.user_id == current_user.id
    ).all()]

    # –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –±–æ—Ç—ã —á–µ—Ä–µ–∑ –º—É–ª—å—Ç–∏-–±–æ—Ç –º–µ–Ω–µ–¥–∂–µ—Ä –æ–¥–Ω–∏–º –∑–∞–ø—Ä–æ—Å–æ–º
    if bot_ids:
        try:
            import requests
            response = requests.post(
                "http://127.0.0.1:3001/stop-bots",
                json={"bot_ids": bot_ids},
                timeout=5
            )
            print(f"[DELETE_ASSISTANT] –û—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã –±–æ—Ç—ã {bot_ids}: {response.status_code}")
        except Exception as e:
            print(f"[DELETE_ASSISTANT] –û—à–∏–±–∫–∞ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –±–æ—Ç–æ–≤ {bot_ids}: {e}")

    # –ü–µ—Ä–µ–¥ —É–¥–∞–ª–µ–Ω–∏–µ–º –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ —É–¥–∞–ª—è–µ–º —Ñ–∏–∑–∏—á–µ—Å–∫–∏–µ —Ñ–∞–π–ª—ã –µ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    try:
        from utils.bot_cleanup import delete_assistant_files
        deleted_files = delete_assistant_files(current_user.id, assistant_id, db)
        print(f"[DELETE_ASSISTANT] –£–¥–∞–ª–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {deleted_files}")
    except Exception as e:
        print(f"[DELETE_ASSISTANT] –û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è —Ñ–∞–π–ª–æ–≤ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞: {e}")

    # –£–¥–∞–ª–∏—Ç—å –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –∏ —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å—É—â–Ω–æ—Å—Ç–∏ (bulk), –∏–∑–±–µ–≥–∞—è –ª–µ–Ω–∏–≤—ã—Ö –∑–∞–≥—Ä—É–∑–æ–∫ –±–æ–ª—å—à–∏—Ö –ø–æ–ª–µ–π
    crud.delete_assistant(db, assistant_id)

    print(f"[DELETE_ASSISTANT] –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç {assistant_id} –∏ {len(bot_ids)} —Å–≤—è–∑–∞–Ω–Ω—ã—Ö –±–æ—Ç–æ–≤ —É–¥–∞–ª–µ–Ω—ã")
    
    return {"ok": True}

# --- Assistant Settings ---

@router.get("/assistants/{assistant_id}/settings")
def get_assistant_settings(assistant_id: int, current_user: models.User = Depends(auth.get_current_user), db: Session = Depends(get_db)):
    """–ü–æ–ª—É—á–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞"""
    assistant = db.query(models.Assistant).filter(
        models.Assistant.id == assistant_id,
        models.Assistant.user_id == current_user.id
    ).first()
    
    if not assistant:
        raise HTTPException(status_code=404, detail="Assistant not found")
    
    return {
        "id": assistant.id,
        "name": assistant.name,
        "ai_model": assistant.ai_model,
        "system_prompt": assistant.system_prompt,
        "is_active": assistant.is_active,
        "website_integration_enabled": assistant.website_integration_enabled
    }

@router.get("/assistants/{assistant_id}/embed-code")
def get_assistant_embed_code(
    assistant_id: int, 
    current_user: models.User = Depends(auth.get_current_user), 
    db: Session = Depends(get_db)
):
    """–ü–æ–ª—É—á–∏—Ç—å embed –∫–æ–¥ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞"""
    assistant = db.query(models.Assistant).filter(
        models.Assistant.id == assistant_id,
        models.Assistant.user_id == current_user.id
    ).first()
    
    if not assistant:
        raise HTTPException(status_code=404, detail="Assistant not found")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –¥–æ–º–µ–Ω—ã —É–∫–∞–∑–∞–Ω—ã –¥–ª—è –≤–∏–¥–∂–µ—Ç–∞
    if not assistant.allowed_domains or assistant.allowed_domains.strip() == "":
        raise HTTPException(
            status_code=400, 
            detail="–î–ª—è –≤–∏–¥–∂–µ—Ç–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —É–∫–∞–∑–∞—Ç—å —Ä–∞–∑—Ä–µ—à–µ–Ω–Ω—ã–µ –¥–æ–º–µ–Ω—ã. –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –∏—Ö –≤ –ø–∞–Ω–µ–ª–∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–æ–º."
        )
    
    from core.app_config import SITE_SECRET
    from datetime import datetime
    import time
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è URL
    from core.app_config import FRONTEND_URL
    
    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–æ–º–µ–Ω–æ–≤ –∏ —Å—Ç–∞–±–∏–ª—å–Ω—ã–π —Ö–µ—à
    import hashlib
    raw_domains = assistant.allowed_domains or ""
    normalized_domains = [
        d.strip().lower().replace('https://', '').replace('http://', '').replace('www.', '').rstrip('/')
        for d in raw_domains.split(',') if d.strip()
    ]
    # –£–±–∏—Ä–∞–µ–º –ø—É—Å—Ç—ã–µ, –¥—É–±–ª–∏ –∏ —Å–æ—Ä—Ç–∏—Ä—É–µ–º –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
    normalized_domains = sorted(list(set([d for d in normalized_domains if d])))
    normalized_domains_str = ",".join(normalized_domains)
    
    domains_hash = hashlib.sha256(normalized_domains_str.encode('utf-8')).hexdigest()
    
    payload = {
        'user_id': current_user.id,
        'assistant_id': assistant_id,
        'type': 'site',
        'allowed_domains': normalized_domains_str,
        'domains_hash': domains_hash,  # –°—Ç–∞–±–∏–ª—å–Ω—ã–π sha256 –æ—Ç –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö –¥–æ–º–µ–Ω–æ–≤
        'issued_at': int(time.time()),  # –í—Ä–µ–º—è –≤—ã–¥–∞—á–∏ —Ç–æ–∫–µ–Ω–∞ (–±–µ–∑ exp, –±–µ—Å—Å—Ä–æ—á–Ω—ã–π)
        'widget_version': getattr(assistant, 'widget_version', 1)
    }
    site_token = jwt.encode(payload, SITE_SECRET, algorithm='HS256')
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º embed –∫–æ–¥ –≤ —Ñ–æ—Ä–º–∞—Ç–µ script tag —Å –≤–µ—Ä—Å–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ–º
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ–º—É –∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –∏–ª–∏ fallback –∫ blue
    widget_theme = getattr(assistant, 'widget_theme', None) or 'blue'
    
    # –ï—Å–ª–∏ –∫–∞—Å—Ç–æ–º–Ω—ã–π —Ü–≤–µ—Ç (HEX), –ø–µ—Ä–µ–¥–∞–µ–º –µ–≥–æ –≤ URL —Å URL-–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ–º
    if widget_theme and widget_theme.startswith('#'):
        from urllib.parse import quote
        theme_param = f"theme={quote(widget_theme)}"
    else:
        theme_param = f"theme={widget_theme}"
    
    embed_code = f'<script src="{FRONTEND_URL}/widget.js?token={site_token}&assistant_id={assistant_id}&{theme_param}&type=floating&host={FRONTEND_URL}&v={domains_hash}" async></script>'
    return {
        "embed_code": embed_code,
        "token": site_token,
        "assistant_id": assistant_id,
        "assistant_name": assistant.name,
        "allowed_domains": normalized_domains_str
    }

@router.post("/validate-widget-token")
def validate_widget_token(token_data: dict, db: Session = Depends(get_db)):
    """–í–∞–ª–∏–¥–∞—Ü–∏—è —Ç–æ–∫–µ–Ω–∞ –≤–∏–¥–∂–µ—Ç–∞ –Ω–∞ –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å –¥–æ–º–µ–Ω–æ–≤"""
    try:
        token = token_data.get('token')
        current_domain = (token_data.get('domain') or '').strip().lower().replace('https://', '').replace('http://', '').replace('www.', '').rstrip('/')
        
        if not token:
            return {"valid": False, "reason": "No token provided"}
            
        from core.app_config import SITE_SECRET
        
        # –î–µ–∫–æ–¥–∏—Ä—É–µ–º —Ç–æ–∫–µ–Ω
        try:
            # –ë–µ—Å—Å—Ä–æ—á–Ω—ã–π —Ç–æ–∫–µ–Ω: –æ—Ç–∫–ª—é—á–∞–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É exp
            payload = jwt.decode(token, SITE_SECRET, algorithms=['HS256'], options={"verify_exp": False})
        except jwt.InvalidTokenError as e:
            return {"valid": False, "reason": f"Invalid token: {str(e)}"}
            
        assistant_id = payload.get('assistant_id')
        if not assistant_id:
            return {"valid": False, "reason": "No assistant_id in token"}
            
        # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –∏–∑ –ë–î
        assistant = db.query(models.Assistant).filter(models.Assistant.id == assistant_id).first()
        if not assistant:
            return {"valid": False, "reason": "Assistant not found"}
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞
        if not getattr(assistant, 'is_active', True):
            return {"valid": False, "reason": "Assistant disabled"}
            
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å –¥–æ–º–µ–Ω–æ–≤ –∏ domains_hash (—Å—Ç–∞–±–∏–ª—å–Ω—ã–π sha256 –æ—Ç –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–≥–æ —Å–ø–∏—Å–∫–∞)
        raw_current = assistant.allowed_domains or ""
        current_domains_list = [
            d.strip().lower().replace('https://', '').replace('http://', '').replace('www.', '').rstrip('/')
            for d in raw_current.split(',') if d.strip()
        ]
        current_domains_list = sorted(list(set([d for d in current_domains_list if d])))
        current_domains_str = ",".join(current_domains_list)
        
        token_domains = payload.get('allowed_domains', "")
        token_domains_hash = payload.get('domains_hash')
        token_widget_version = int(payload.get('widget_version') or 1)
        
        import hashlib
        current_hash = hashlib.sha256(current_domains_str.encode('utf-8')).hexdigest()
        
        if token_domains_hash != current_hash:
            return {"valid": False, "reason": "domains changed", "allowed_domains": current_domains_str}

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–µ—Ä—Å–∏—é –≤–∏–¥–∂–µ—Ç–∞ (—Ç–æ—á–µ—á–Ω—ã–π –æ—Ç–∑—ã–≤)
        current_widget_version = int(getattr(assistant, 'widget_version', 1) or 1)
        if token_widget_version != current_widget_version:
            return {"valid": False, "reason": "version changed", "allowed_domains": current_domains_str}
            
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ç–µ–∫—É—â–∏–π –¥–æ–º–µ–Ω —Ä–∞–∑—Ä–µ—à–µ–Ω
        if not current_domains_str.strip():
            return {"valid": False, "reason": "No domains configured"}
            
        allowed_domains = current_domains_list
        
        domain_allowed = True
        if current_domain:
            domain_allowed = any(current_domain == allowed or current_domain.endswith('.' + allowed) 
                               for allowed in allowed_domains)
        
        if not domain_allowed:
            return {"valid": False, "reason": "Domain not allowed", "allowed_domains": allowed_domains}
            
        # –ú–æ–∂–Ω–æ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –≤–µ—Ä–Ω—É—Ç—å user_id –≤–ª–∞–¥–µ–ª—å—Ü–∞, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ –¥–ª—è —Ñ—Ä–æ–Ω—Ç–∞
        return {"valid": True, "assistant_id": assistant_id, "allowed_domains": current_domains_str, "user_id": assistant.user_id}
    except Exception as e:
        return {"valid": False, "reason": f"Validation error: {str(e)}"}

@router.post("/widgets")
def create_widget_token(data: dict, current_user: models.User = Depends(auth.get_current_user), db: Session = Depends(get_db)):
    """–í—ã–¥–∞—Ç—å embed-–∫–æ–¥ + —Å–≤–µ–∂–∏–π JWT –¥–ª—è –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ (–≤–∏–¥–∂–µ—Ç–∞)."""
    assistant_id = data.get('assistant_id')
    if not assistant_id:
        raise HTTPException(status_code=400, detail="assistant_id required")

    assistant = db.query(models.Assistant).filter(
        models.Assistant.id == assistant_id,
        models.Assistant.user_id == current_user.id
    ).first()
    if not assistant:
        raise HTTPException(status_code=404, detail="Assistant not found")

    if not assistant.allowed_domains or assistant.allowed_domains.strip() == "":
        raise HTTPException(status_code=400, detail="–î–ª—è –≤–∏–¥–∂–µ—Ç–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —É–∫–∞–∑–∞—Ç—å —Ä–∞–∑—Ä–µ—à–µ–Ω–Ω—ã–µ –¥–æ–º–µ–Ω—ã")

    from core.app_config import SITE_SECRET
    from core.app_config import FRONTEND_URL
    import hashlib, time

    raw_domains = assistant.allowed_domains or ""
    normalized_domains = [
        d.strip().lower().replace('https://', '').replace('http://', '').replace('www.', '').rstrip('/')
        for d in raw_domains.split(',') if d.strip()
    ]
    normalized_domains = sorted(list(set([d for d in normalized_domains if d])))
    normalized_domains_str = ",".join(normalized_domains)
    domains_hash = hashlib.sha256(normalized_domains_str.encode('utf-8')).hexdigest()

    payload = {
        'user_id': current_user.id,
        'assistant_id': assistant.id,
        'type': 'site',
        'allowed_domains': normalized_domains_str,
        'domains_hash': domains_hash,
        'issued_at': int(time.time()),
        'widget_version': getattr(assistant, 'widget_version', 1)
    }
    site_token = jwt.encode(payload, SITE_SECRET, algorithm='HS256')

    widget_theme = getattr(assistant, 'widget_theme', None) or 'blue'
    if widget_theme and widget_theme.startswith('#'):
        from urllib.parse import quote
        theme_param = f"theme={quote(widget_theme)}"
    else:
        theme_param = f"theme={widget_theme}"

    embed_code = f'<script src="{FRONTEND_URL}/widget.js?token={site_token}&assistant_id={assistant.id}&{theme_param}&type=floating&host={FRONTEND_URL}&v={domains_hash}" async></script>'
    return {
        "widget_id": assistant.id,
        "site_token": site_token,
        "embed_code": embed_code,
        "allowed_domains": normalized_domains_str
    }


@router.post("/widget-config")
def get_widget_config_by_token(token_data: dict, db: Session = Depends(get_db)):
    """–ü–æ–ª—É—á–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –≤–∏–¥–∂–µ—Ç–∞ –ø–æ —Ç–æ–∫–µ–Ω—É –¥–ª—è –≤–∏–¥–∂–µ—Ç–∞"""
    try:
        print(f"[WIDGET_CONFIG] üì• –ó–∞–ø—Ä–æ—Å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –≤–∏–¥–∂–µ—Ç–∞: {token_data}")
        
        token = token_data.get('token')
        
        if not token:
            print("[WIDGET_CONFIG] ‚ùå –¢–æ–∫–µ–Ω –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω")
            return {"success": False, "reason": "No token provided"}
            
        from core.app_config import SITE_SECRET
        
        # –î–µ–∫–æ–¥–∏—Ä—É–µ–º —Ç–æ–∫–µ–Ω
        try:
            # –ë–µ—Å—Å—Ä–æ—á–Ω—ã–π —Ç–æ–∫–µ–Ω: –æ—Ç–∫–ª—é—á–∞–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É exp
            payload = jwt.decode(token, SITE_SECRET, algorithms=['HS256'], options={"verify_exp": False})
            print(f"[WIDGET_CONFIG] üîì –¢–æ–∫–µ–Ω –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω: assistant_id={payload.get('assistant_id')}")
        except jwt.InvalidTokenError as e:
            print(f"[WIDGET_CONFIG] ‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π —Ç–æ–∫–µ–Ω: {e}")
            return {"success": False, "reason": f"Invalid token: {str(e)}"}
            
        assistant_id = payload.get('assistant_id')
        if not assistant_id:
            print("[WIDGET_CONFIG] ‚ùå –í —Ç–æ–∫–µ–Ω–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç assistant_id")
            return {"success": False, "reason": "No assistant_id in token"}
            
        # –ü–æ–ª—É—á–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –∏–∑ –ë–î
        assistant = db.query(models.Assistant).filter(models.Assistant.id == assistant_id).first()
        if not assistant:
            print(f"[WIDGET_CONFIG] ‚ùå –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç —Å ID {assistant_id} –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return {"success": False, "reason": "Assistant not found"}
            
        print(f"[WIDGET_CONFIG] üìã –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç –Ω–∞–π–¥–µ–Ω: {assistant.name}")
        print(f"[WIDGET_CONFIG] üë§ –û–ø–µ—Ä–∞—Ç–æ—Ä: {getattr(assistant, 'operator_name', '–ù–ï –ó–ê–î–ê–ù–û')}")
        print(f"[WIDGET_CONFIG] üè¢ –ö–æ–º–ø–∞–Ω–∏—è: {getattr(assistant, 'business_name', '–ù–ï –ó–ê–î–ê–ù–û')}")
        print(f"[WIDGET_CONFIG] üé® –¢–µ–º–∞: {getattr(assistant, 'widget_theme', '–ù–ï –ó–ê–î–ê–ù–û')}")
        print(f"[WIDGET_CONFIG] üñºÔ∏è –ê–≤–∞—Ç–∞—Ä: {getattr(assistant, 'avatar_url', '–ù–ï –ó–ê–î–ê–ù–û')}")
        print(f"[WIDGET_CONFIG] ‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏: {getattr(assistant, 'widget_settings', {})}")
            
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –≤–∏–¥–∂–µ—Ç–∞ —Å fallback –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
        config = {
            "success": True,
            "config": {
                "operator_name": getattr(assistant, 'operator_name', None) or '–ü–æ–¥–¥–µ—Ä–∂–∫–∞',
                "business_name": getattr(assistant, 'business_name', None) or '–ù–∞—à–∞ –∫–æ–º–ø–∞–Ω–∏—è',
                "avatar_url": getattr(assistant, 'avatar_url', None),
                "widget_theme": getattr(assistant, 'widget_theme', None) or 'blue',
                "widget_settings": getattr(assistant, 'widget_settings', {}) or {},
                "assistant_id": assistant_id
            }
        }
        
        print(f"[WIDGET_CONFIG] ‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –≤–æ–∑–≤—Ä–∞—â–µ–Ω–∞: {config['config']}")
        return config
        
    except Exception as e:
        print(f"[WIDGET_CONFIG] üí• –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {e}")
        import traceback
        print(f"[WIDGET_CONFIG] Traceback: {traceback.format_exc()}")
        return {"success": False, "reason": f"Config error: {str(e)}"}

@router.post("/assistants/{assistant_id}/widget-settings")
def save_assistant_widget_settings(
    assistant_id: int,
    settings: dict,
    current_user: models.User = Depends(auth.get_current_user),
    db: Session = Depends(get_db)
):
    """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –≤–∏–¥–∂–µ—Ç–∞ –¥–ª—è –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞"""
    assistant = db.query(models.Assistant).filter(
        models.Assistant.id == assistant_id,
        models.Assistant.user_id == current_user.id
    ).first()
    
    if not assistant:
        raise HTTPException(status_code=404, detail="Assistant not found")
    
    try:
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –≤–∏–¥–∂–µ—Ç–∞ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
        if 'operator_name' in settings:
            assistant.operator_name = settings['operator_name']
        if 'business_name' in settings:
            assistant.business_name = settings['business_name']
        if 'avatar_url' in settings:
            assistant.avatar_url = settings['avatar_url']
        if 'widget_theme' in settings:
            assistant.widget_theme = settings['widget_theme']
        if 'allowed_domains' in settings:
            assistant.allowed_domains = settings['allowed_domains']
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –≤–∏–¥–∂–µ—Ç–∞ (–ø–æ–∑–∏—Ü–∏—è, —Ä–∞–∑–º–µ—Ä –∫–Ω–æ–ø–∫–∏ –∏ —Ç.–¥.)
        widget_settings = settings.get('widget_settings', {})
        if widget_settings or 'widget_settings' in settings:
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –∏ –Ω–æ–≤—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
            current_settings = assistant.widget_settings or {}
            current_settings.update(widget_settings)
            assistant.widget_settings = current_settings
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –≤—Ä–µ–º—è –∏–∑–º–µ–Ω–µ–Ω–∏—è
        assistant.updated_at = datetime.utcnow()
        
        db.commit()
        db.refresh(assistant)
        
        print(f"[WIDGET_SETTINGS] –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –≤–∏–¥–∂–µ—Ç–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –¥–ª—è –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ {assistant_id}: {settings}")
        
        # –ò–Ω–≤–∞–ª–∏–¥–∏—Ä—É–µ–º –∫—ç—à –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞
        invalidate_assistant_cache(assistant_id)
        
        return {
            "success": True,
            "message": "–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –≤–∏–¥–∂–µ—Ç–∞ —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã",
            "settings": {
                "operator_name": assistant.operator_name,
                "business_name": assistant.business_name,
                "avatar_url": assistant.avatar_url,
                "widget_theme": assistant.widget_theme,
                "allowed_domains": assistant.allowed_domains,
                "widget_settings": assistant.widget_settings
            }
        }
    except Exception as e:
        print(f"[WIDGET_SETTINGS] –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–∫ –≤–∏–¥–∂–µ—Ç–∞: {e}")
        db.rollback()
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–∫: {str(e)}")

@router.post("/upload/avatar")
async def upload_avatar(
    file: UploadFile = File(...),
    current_user: models.User = Depends(auth.get_current_user),
    db: Session = Depends(get_db)
):
    """–ó–∞–≥—Ä—É–∑–∫–∞ –∞–≤–∞—Ç–∞—Ä–∞ –¥–ª—è –≤–∏–¥–∂–µ—Ç–∞"""
    from validators.file_validator import file_validator
    import os
    import uuid
    from pathlib import Path
    
    try:
        # –ß–∏—Ç–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞
        content = await file.read()
        await file.seek(0)  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —É–∫–∞–∑–∞—Ç–µ–ª—å –≤ –Ω–∞—á–∞–ª–æ
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —ç—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        if not file.content_type or not file.content_type.startswith('image/'):
            raise HTTPException(status_code=400, detail="–§–∞–π–ª –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ (–º–∞–∫—Å–∏–º—É–º 5MB)
        if len(content) > 5 * 1024 * 1024:
            raise HTTPException(status_code=400, detail="–†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ –Ω–µ –¥–æ–ª–∂–µ–Ω –ø—Ä–µ–≤—ã—à–∞—Ç—å 5MB")
        
        # –†–∞–∑—Ä–µ—à–µ–Ω–Ω—ã–µ —Ç–∏–ø—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        allowed_types = ['image/jpeg', 'image/jpg', 'image/png', 'image/webp']
        if file.content_type not in allowed_types:
            raise HTTPException(status_code=400, detail="–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ JPEG, PNG –∏ WebP –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —É–Ω–∏–∫–∞–ª—å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞
        file_extension = Path(file.filename).suffix.lower()
        if not file_extension:
            file_extension = '.jpg'  # –¥–µ—Ñ–æ–ª—Ç–Ω–æ–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ
        
        unique_filename = f"{uuid.uuid4().hex}{file_extension}"
        
        # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É avatars –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
        avatars_dir = Path("uploads/avatars")
        avatars_dir.mkdir(parents=True, exist_ok=True)
        
        file_path = avatars_dir / unique_filename
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª
        with open(file_path, "wb") as f:
            f.write(content)
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º URL –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∫ —Ñ–∞–π–ª—É
        avatar_url = f"/uploads/avatars/{unique_filename}"
        
        logger.info(f"Avatar uploaded successfully: {file_path} by user {current_user.id}")
        
        return {
            "success": True,
            "url": avatar_url,
            "message": "–ê–≤–∞—Ç–∞—Ä —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω"
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Avatar upload error: {e}")
        raise HTTPException(status_code=500, detail="–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∞–≤–∞—Ç–∞—Ä–∞")

@router.post("/assistants/{assistant_id}/website-integration")
def toggle_website_integration(
    assistant_id: int,
    data: dict,
    current_user: models.User = Depends(auth.get_current_user),
    db: Session = Depends(get_db)
):
    """–í–∫–ª—é—á–∏—Ç—å/–≤—ã–∫–ª—é—á–∏—Ç—å –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é —Å —Å–∞–π—Ç–æ–º –¥–ª—è –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞"""
    assistant = db.query(models.Assistant).filter(
        models.Assistant.id == assistant_id,
        models.Assistant.user_id == current_user.id
    ).first()
    
    if not assistant:
        raise HTTPException(status_code=404, detail="Assistant not found")
    
    enabled = data.get('enabled', False)
    assistant.website_integration_enabled = enabled
    db.commit()
    
    return {
        "success": True,
        "message": f"–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å —Å–∞–π—Ç–æ–º {'–≤–∫–ª—é—á–µ–Ω–∞' if enabled else '–≤—ã–∫–ª—é—á–µ–Ω–∞'}",
        "website_integration_enabled": enabled
    }

@router.get("/assistants/{assistant_id}/widget-settings")
def get_assistant_widget_settings(
    assistant_id: int,
    current_user: models.User = Depends(auth.get_current_user),
    db: Session = Depends(get_db)
):
    """–ü–æ–ª—É—á–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –≤–∏–¥–∂–µ—Ç–∞ –¥–ª—è –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞"""
    assistant = db.query(models.Assistant).filter(
        models.Assistant.id == assistant_id,
        models.Assistant.user_id == current_user.id
    ).first()
    
    if not assistant:
        raise HTTPException(status_code=404, detail="Assistant not found")
    
    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
    default_settings = {
        "theme": "blue",
        "position": "bottom-right",
        "welcomeMessage": "–ü—Ä–∏–≤–µ—Ç! –ß–µ–º –º–æ–≥—É –ø–æ–º–æ—á—å?",
        "buttonText": "–ü–æ–¥–¥–µ—Ä–∂–∫–∞",
        "showAvatar": True,
        "showOnlineStatus": True,
        "buttonSize": 80,
        "borderRadius": 16
    }
    
    return {
        "settings": default_settings,
        "assistant_id": assistant_id
    }


# --- Website ingestion ---

class IngestWebsiteRequest(BaseModel):
    url: str


@router.post("/assistants/{assistant_id}/ingest-website")
def ingest_website_for_assistant(
    assistant_id: int,
    req: IngestWebsiteRequest,
    current_user: models.User = Depends(auth.get_current_user),
    db: Session = Depends(get_db)
):
    """–ò–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞—Ç—å –æ–¥–Ω—É —Å—Ç—Ä–∞–Ω–∏—Ü—É —Å–∞–π—Ç–∞ –≤ –∑–Ω–∞–Ω–∏—è –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ (single-page mode)."""
    assistant = db.query(models.Assistant).filter(
        models.Assistant.id == assistant_id,
        models.Assistant.user_id == current_user.id
    ).first()
    if not assistant:
        raise HTTPException(status_code=404, detail="Assistant not found")

    # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ single-page —Ä–µ–∂–∏–º - —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ
    try:
        result = _crawl_and_index_single_page(
            db=db, 
            user_id=current_user.id, 
            assistant_id=assistant_id, 
            url=req.url
        )
        return {"ok": True, **result}
    except ValueError as e:
        # –û—à–∏–±–∫–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ (robots.txt, –Ω–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ç–∏–ø –∏ —Ç.–¥.)
        raise HTTPException(status_code=403, detail=str(e))
    except Exception as e:
        logger.error(f"Single page indexing failed: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"–ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –Ω–µ —É–¥–∞–ª–∞—Å—å: {e}")


def _crawl_and_index_single_page(*, db: Session, user_id: int, assistant_id: int, url: str) -> dict:
    """–°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è –æ–¥–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π."""
    from services.website_crawler import website_crawler
    from services.embeddings_service import embeddings_service
    from urllib.parse import urlparse
    from urllib.robotparser import RobotFileParser
    import requests
    from pathlib import Path

    # 1. –í–∞–ª–∏–¥–∞—Ü–∏—è URL
    try:
        parsed = urlparse(url)
        if parsed.scheme not in ["http", "https"]:
            raise ValueError("URL –¥–æ–ª–∂–µ–Ω –Ω–∞—á–∏–Ω–∞—Ç—å—Å—è —Å http:// –∏–ª–∏ https://")
        if not parsed.netloc:
            raise ValueError("–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π URL")
    except Exception:
        raise ValueError("–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π URL")

    # 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ robots.txt –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ø—É—Ç–∏
    try:
        robots_url = f"{parsed.scheme}://{parsed.netloc}/robots.txt"
        rp = RobotFileParser()
        rp.set_url(robots_url)
        rp.read()
        if not rp.can_fetch("ChatAI-Crawler/1.0", url):
            raise ValueError(f"–ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∑–∞–ø—Ä–µ—â–µ–Ω–∞ robots.txt –¥–ª—è {url}")
    except ValueError:
        raise  # –ø–µ—Ä–µ–±—Ä–∞—Å—ã–≤–∞–µ–º –Ω–∞—à–∏ –æ—à–∏–±–∫–∏
    except Exception:
        pass  # –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º —Å–µ—Ç–µ–≤—ã–µ –æ—à–∏–±–∫–∏ robots.txt

    # 3. –°–∫–∞—á–∏–≤–∞–Ω–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    headers = {"User-Agent": "ChatAI-Crawler/1.0"}
    resp = None
    try:
        resp = requests.get(url, headers=headers, timeout=30, allow_redirects=True)
        resp.raise_for_status()
        
        # –õ–æ–≥–∏—Ä—É–µ–º —Ä–µ–¥–∏—Ä–µ–∫—Ç
        if resp.url != url:
            logger.info(f"Redirected from {url} to {resp.url}")
            url = resp.url  # –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π URL
            parsed = urlparse(url)
    except requests.RequestException as e:
        raise ValueError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—É: {e}")

    if resp is None:
        raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç —Å–µ—Ä–≤–µ—Ä–∞")

    # 4. –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ (2MB)
    MAX_SIZE = 2 * 1024 * 1024  # 2MB
    content_length = len(resp.content)
    if content_length > MAX_SIZE:
        logger.warning(f"Content truncated: {content_length} > {MAX_SIZE}")
        content = resp.content[:MAX_SIZE]
    else:
        content = resp.content

    # 5. –û–±—Ä–∞–±–æ—Ç–∫–∞ content-type (—Å –∑–∞—â–∏—Ç–æ–π –æ—Ç –Ω–µ–≤–∞–ª–∏–¥–Ω—ã—Ö –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤)
    try:
        headers_obj = getattr(resp, "headers", {}) or {}
        # –ü—Ä–∏–≤–æ–¥–∏–º –∫ str –Ω–∞ —Å–ª—É—á–∞–π –Ω–µ—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤
        content_type_raw = headers_obj.get("Content-Type") or headers_obj.get("content-type") or ""
        content_type = str(content_type_raw).lower()
    except Exception:
        content_type = ""

    # –ï—Å–ª–∏ —Å–µ—Ä–≤–µ—Ä –Ω–µ –æ—Ç–¥–∞–ª Content-Type ‚Äî –¥–µ–ª–∞–µ–º –≥—Ä—É–±–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Å–∏–≥–Ω–∞—Ç—É—Ä–∞–º
    if not content_type:
        try:
            sample = (content[:1024] if isinstance(content, (bytes, bytearray)) else b"")
            sample_lower = sample.lower()
            if sample_lower.startswith(b"%pdf"):
                content_type = "application/pdf"
            elif b"<html" in sample_lower or b"<!doctype html" in sample_lower:
                content_type = "text/html"
            else:
                # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é —Å—á–∏—Ç–∞–µ–º —Ç–µ–∫—Å—Ç–æ–º
                content_type = "text/plain"
        except Exception:
            content_type = "text/plain"
    if "text/html" in content_type:
        text = website_crawler._extract_visible_text(content.decode('utf-8', errors='ignore'))
    elif "text/plain" in content_type:
        text = content.decode('utf-8', errors='ignore')
    elif "application/pdf" in content_type:
        # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ: –ø–æ–¥–¥–µ—Ä–∂–∫–∞ PDF
        try:
            import PyPDF2
            from io import BytesIO
            pdf_reader = PyPDF2.PdfReader(BytesIO(content))
            text = "\n".join([page.extract_text() for page in pdf_reader.pages])
        except Exception as e:
            logger.warning(f"PDF extraction failed: {e}")
            raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –∏–∑ PDF")
    else:
        raise ValueError(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π content-type: {content_type}")

    if len(text.strip()) < 100:
        raise ValueError("–°–ª–∏—à–∫–æ–º –º–∞–ª–æ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ")

    # 6. –û—á–∏—Å—Ç–∫–∞ —á–µ—Ä–µ–∑ GPT (single-page prompt)
    cleaned_text = _clean_single_page_via_gpt(text, url, user_id=user_id)

    # 7. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–∞–π–ª–∞ —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–º –∏–º–µ–Ω–µ–º
    filename = _make_single_page_filename(parsed.netloc, parsed.path, url)
    file_path = FileValidator.get_safe_upload_path(user_id, filename)
    file_path.write_text(cleaned_text, encoding='utf-8')

    # 8. –°–æ–∑–¥–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞ —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –¥—É–±–ª–µ–π –ø–æ URL —Ö–µ—à—É
    import hashlib as _hashlib
    url_hash_full = _hashlib.md5(url.encode('utf-8')).hexdigest()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞ —Å —Ç–∞–∫–∏–º –∂–µ URL (–ø–æ —Ö–µ—à—É –≤ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞)
    existing_doc = db.query(models.Document).filter(
        models.Document.user_id == user_id,
        models.Document.filename.like(f"%{url_hash_full[:6]}.md")
    ).first()
    
    if existing_doc:
        doc = existing_doc
        logger.info(f"–ù–∞–π–¥–µ–Ω —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –¥–æ–∫—É–º–µ–Ω—Ç –¥–ª—è URL {url}: {existing_doc.filename}")
    else:
        doc = crud.create_document(
            db,
            user_id=user_id,
            filename=file_path.name,
            size=len(cleaned_text.encode('utf-8'))
        )
        # –ü–∏—à–µ–º doc_hash –¥–ª—è –≤–æ–∑–º–æ–∂–Ω–æ–π –¥–∞–ª—å–Ω–µ–π—à–µ–π –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏
        try:
            doc.doc_hash = _hashlib.md5(cleaned_text.encode('utf-8')).hexdigest()
            db.commit()
            logger.info(f"–°–æ–∑–¥–∞–Ω –Ω–æ–≤—ã–π –¥–æ–∫—É–º–µ–Ω—Ç –¥–ª—è URL {url}: {file_path.name}")
        except Exception:
            db.rollback()

    # 9. –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∫–∞–∫ 'website_single'
    # –ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –Ω–æ–≤–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞
    if not existing_doc:
        embeddings_service.index_document(
            doc_id=doc.id,
            user_id=user_id,
            assistant_id=assistant_id,
            text=cleaned_text,
            doc_type='website_single',
            importance=10,
            db=db,
        )

    # 10. –ü—Ä–∏–≤—è–∑–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∫ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç—É –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π (–¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ UI)
    try:
        # –°–æ–∑–¥–∞–µ–º —Å–≤—è–∑—å –≤ –∑–Ω–∞–Ω–∏—è—Ö —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—ë –µ—â—ë –Ω–µ—Ç
        exists_uk = db.query(models.UserKnowledge.id).filter(
            models.UserKnowledge.user_id == user_id,
            models.UserKnowledge.assistant_id == assistant_id,
            models.UserKnowledge.doc_id == doc.id,
            models.UserKnowledge.type == 'original',
        ).first()
        if not exists_uk:
            knowledge_entry = models.UserKnowledge(
                user_id=user_id,
                assistant_id=assistant_id,
                doc_id=doc.id,
                content=cleaned_text,
                type='original',
                doc_type='website_single',
                importance=10,
            )
            db.add(knowledge_entry)
            db.commit()
            logger.info(f"–°–æ–∑–¥–∞–Ω–∞ —Å–≤—è–∑—å –∑–Ω–∞–Ω–∏–π –¥–ª—è doc_id={doc.id}, assistant_id={assistant_id}")
        else:
            logger.info(f"–°–≤—è–∑—å –∑–Ω–∞–Ω–∏–π —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –¥–ª—è doc_id={doc.id}, assistant_id={assistant_id}")
    except Exception as _e:
        logger.warning(f"Failed to create UserKnowledge for website_single doc_id={doc.id}: {_e}")
        db.rollback()

    return {
        "doc_id": doc.id,
        "url": url,
        "chars_indexed": len(cleaned_text)
    }


def _bg_crawl_and_index(user_id: int, assistant_id: int, opts: dict):
    from database.connection import SessionLocal
    from services.website_crawler import website_crawler, CrawlOptions
    from services.embeddings_service import embeddings_service
    from database import models as m
    import hashlib
    import logging as _logging

    _log = _logging.getLogger(__name__)
    db = SessionLocal()
    try:
        url = opts.get("url")
        crawl_opts = CrawlOptions(
            max_pages=int(opts.get("max_pages", 20)),
            same_domain_only=bool(opts.get("same_domain_only", True)),
            include_sitemap=bool(opts.get("include_sitemap", True)),
            allowed_paths=opts.get("allowed_paths"),
        )
        pages = website_crawler.crawl(url, crawl_opts)

        # –§–æ—Ä–º–∏—Ä—É–µ–º "–≥—Ä—è–∑–Ω—ã–π" —Ç–µ–∫—Å—Ç
        dirty_text = "\n\n".join([f"URL: {u}\n\n{text}" for (u, text) in pages])

        # –û—á–∏—â–∞–µ–º/—Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–µ–º —á–µ—Ä–µ–∑ GPT
        cleaned_text = _clean_website_text_via_gpt(dirty_text, user_id=user_id)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ —Ñ–∞–π–ª "–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è —Å —Å–∞–π—Ç–∞*.txt" –≤ uploads/<user_id>/
        filename = _make_site_filename()
        file_path = FileValidator.get_safe_upload_path(user_id, filename)
        file_path.write_text(cleaned_text, encoding='utf-8')

        # –°–æ–∑–¥–∞—ë–º –∑–∞–ø–∏—Å—å –¥–æ–∫—É–º–µ–Ω—Ç–∞
        doc = crud.create_document(db, user_id=user_id, filename=file_path.name, size=len(cleaned_text.encode('utf-8')))

        # –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –ø–æ —á–∞–Ω–∫–∞–º –∫–∞–∫ –¥–æ–∫—É–º–µ–Ω—Ç —Ç–∏–ø–∞ 'website'
        embeddings_service.index_document(
            doc_id=doc.id,
            user_id=user_id,
            assistant_id=assistant_id,
            text=cleaned_text,
            doc_type='website',
            importance=10,
            db=db,
        )

        _log.info(f"Website ingested: {url}, pages={len(pages)} for assistant={assistant_id}")
    except Exception as e:
        _log.warning(f"[INGEST_WEBSITE] failed: {e}")
    finally:
        db.close()


def _crawl_and_index_sync(*, db: Session, user_id: int, assistant_id: int, opts: dict) -> dict:
    """–°–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –∫—Ä–∞—É–ª–∏–Ω–≥ + –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è 1 —Å—Ç—Ä–∞–Ω–∏—Ü—ã)."""
    from services.website_crawler import website_crawler, CrawlOptions
    from services.embeddings_service import embeddings_service
    import hashlib

    url = opts.get("url")
    crawl_opts = CrawlOptions(
        max_pages=int(opts.get("max_pages", 1) or 1),
        same_domain_only=bool(opts.get("same_domain_only", True)),
        include_sitemap=bool(opts.get("include_sitemap", False)),
        allowed_paths=opts.get("allowed_paths") or None,
    )
    pages = website_crawler.crawl(url, crawl_opts)

    dirty_text = "\n\n".join([f"URL: {u}\n\n{text}" for (u, text) in pages])
    cleaned_text = _clean_website_text_via_gpt(dirty_text, user_id=user_id)

    filename = _make_site_filename()
    file_path = FileValidator.get_safe_upload_path(user_id, filename)
    file_path.write_text(cleaned_text, encoding='utf-8')

    doc = crud.create_document(db, user_id=user_id, filename=file_path.name, size=len(cleaned_text.encode('utf-8')))

    embeddings_service.index_document(
        doc_id=doc.id,
        user_id=user_id,
        assistant_id=assistant_id,
        text=cleaned_text,
        doc_type='website',
        importance=10,
        db=db,
    )
    return {"pages_indexed": len(pages), "doc_id": doc.id}


def _make_site_filename() -> str:
    from datetime import datetime
    # –ë–∞–∑–æ–≤–æ–µ –∏–º—è —Ñ–∞–π–ª–∞ –Ω–∞ —Ä—É—Å—Å–∫–æ–º, –¥–æ–±–∞–≤–ª—è–µ–º –¥–∞—Ç—É/–≤—Ä–µ–º—è –¥–ª—è —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏
    ts = datetime.now().strftime('%Y-%m-%d_%H-%M')
    return f"–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è —Å —Å–∞–π—Ç–∞ {ts}.txt"


def _make_single_page_filename(host: str, path: str, url: str = None) -> str:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞ –¥–ª—è single-page: –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è —Å —Å–∞–π—Ç–∞ ‚Äî host/path YYYY-MM-DD_HH-MM-SS.md"""
    from datetime import datetime
    import re
    import hashlib
    
    # –û—á–∏—â–∞–µ–º path –æ—Ç —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª–æ–≤ –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ–≥–æ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
    clean_path = re.sub(r'[^\w\-_./]', '', path or '/').strip('/')
    if not clean_path:
        clean_path = 'main'
    
    # –£–∫–æ—Ä–∞—á–∏–≤–∞–µ–º –µ—Å–ª–∏ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ–µ
    if len(clean_path) > 50:
        clean_path = clean_path[:50]
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–µ–∫—É–Ω–¥—ã –¥–ª—è –±–æ–ª—å—à–µ–π —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏ + –∫–æ—Ä–æ—Ç–∫–∏–π —Ö–µ—à URL
    ts = datetime.utcnow().strftime('%Y-%m-%d_%H-%M-%S')
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–æ—Ç–∫–∏–π —Ö–µ—à URL –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –¥—É–±–ª–µ–π –æ–¥–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    if url:
        url_hash = hashlib.md5(url.encode('utf-8')).hexdigest()[:6]
        return f"–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è —Å —Å–∞–π—Ç–∞ ‚Äî {host}{clean_path} {ts}_{url_hash}.md"
    else:
        return f"–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è —Å —Å–∞–π—Ç–∞ ‚Äî {host}{clean_path} {ts}.md"


def _clean_single_page_via_gpt(dirty_text: str, source_url: str, user_id: int) -> str:
    """GPT –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è –æ–¥–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–º –ø—Ä–æ–º–ø—Ç–æ–º."""
    system_prompt = (
        "–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É –≤–µ–±-–∫–æ–Ω—Ç–µ–Ω—Ç–∞. –ü–æ–ª—É—á–∞–µ—à—å —Å—ã—Ä–æ–π —Ç–µ–∫—Å—Ç –æ–¥–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å–∞–π—Ç–∞.\n"
        "–ó–∞–¥–∞—á–∞: –∏–∑–≤–ª–µ—á—å –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞—Ç—å –∫–ª—é—á–µ–≤—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ —Ñ–æ—Ä–º–∞—Ç–µ Markdown.\n\n"
        
        "–ê–ù–ê–õ–ò–ó –ö–û–ù–¢–ï–ù–¢–ê:\n"
        "1. –û–ø—Ä–µ–¥–µ–ª–∏ —Ç–∏–ø –∫–æ–Ω—Ç–µ–Ω—Ç–∞ (–≥–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞, —É—Å–ª—É–≥–∏, –ø—Ä–æ–¥—É–∫—Ç, –±–ª–æ–≥-–ø–æ—Å—Ç, –∫–æ–Ω—Ç–∞–∫—Ç—ã –∏ —Ç.–¥.)\n"
        "2. –í—ã–¥–µ–ª–∏ –æ—Å–Ω–æ–≤–Ω—É—é —Ç–µ–º—É –∏ —Ü–µ–ª—å —Å—Ç—Ä–∞–Ω–∏—Ü—ã\n"
        "3. –ò–∑–≤–ª–µ–∫–∏ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é, —É–±–µ—Ä–∏ –Ω–∞–≤–∏–≥–∞—Ü–∏—é, —Ñ—É—Ç–µ—Ä—ã, —Ä–µ–∫–ª–∞–º—É\n"
        "4. –°–æ—Ö—Ä–∞–Ω–∏ –≤–∞–∂–Ω—ã–µ –¥–µ—Ç–∞–ª–∏: —Ü–µ–Ω—ã, —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏, –¥–∞—Ç—ã, –∫–æ–Ω—Ç–∞–∫—Ç—ã\n\n"
        
        "–°–¢–†–£–ö–¢–£–†–ê –í–´–í–û–î–ê:\n"
        "–°–æ–∑–¥–∞–π –∞–¥–∞–ø—Ç–∏–≤–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞:\n\n"
        
        "**–î–ª—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã—Ö —Å—Ç—Ä–∞–Ω–∏—Ü:**\n"
        "# [–ó–∞–≥–æ–ª–æ–≤–æ–∫ —Å—Ç—Ä–∞–Ω–∏—Ü—ã]\n"
        "## –ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ\n"
        "## –ö–ª—é—á–µ–≤—ã–µ –º–æ–º–µ–Ω—Ç—ã\n"
        "## –î–µ—Ç–∞–ª–∏ –∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏\n"
        "## –ö–æ–Ω—Ç–∞–∫—Ç–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è (–µ—Å–ª–∏ –µ—Å—Ç—å)\n\n"
        
        "**–î–ª—è —Å—Ç—Ä–∞–Ω–∏—Ü —É—Å–ª—É–≥/–ø—Ä–æ–¥—É–∫—Ç–æ–≤:**\n"
        "# [–ù–∞–∑–≤–∞–Ω–∏–µ —É—Å–ª—É–≥–∏/–ø—Ä–æ–¥—É–∫—Ç–∞]\n"
        "## –û–ø–∏—Å–∞–Ω–∏–µ\n"
        "## –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏/–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏\n"
        "## –°—Ç–æ–∏–º–æ—Å—Ç—å (–µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω–∞)\n"
        "## –£—Å–ª–æ–≤–∏—è –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è\n\n"
        
        "**–î–ª—è –±–ª–æ–≥-–ø–æ—Å—Ç–æ–≤/—Å—Ç–∞—Ç–µ–π:**\n"
        "# [–ó–∞–≥–æ–ª–æ–≤–æ–∫ —Å—Ç–∞—Ç—å–∏]\n"
        "## –û—Å–Ω–æ–≤–Ω—ã–µ —Ç–µ–∑–∏—Å—ã\n"
        "## –ö–ª—é—á–µ–≤—ã–µ —Ñ–∞–∫—Ç—ã\n"
        "## –í—ã–≤–æ–¥—ã\n\n"
        
        "–ü–†–ê–í–ò–õ–ê:\n"
        "- –ò—Å–ø–æ–ª—å–∑—É–π —Ç–æ–ª—å–∫–æ –Ω–∞–π–¥–µ–Ω–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é\n"
        "- –£–±–µ—Ä–∏ –ø–æ–≤—Ç–æ—Ä—ã –∏ –º–∞—Ä–∫–µ—Ç–∏–Ω–≥–æ–≤—ã–µ –∫–ª–∏—à–µ\n"
        "- –°–æ—Ö—Ä–∞–Ω—è–π —á–∏—Å–ª–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –∏ —Ç–æ—á–Ω—ã–µ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏\n"
        "- –ì—Ä—É–ø–ø–∏—Ä—É–π –ø–æ—Ö–æ–∂—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é\n"
        "- –ï—Å–ª–∏ —Ä–∞–∑–¥–µ–ª –ø—É—Å—Ç–æ–π ‚Äî –ù–ï –≤–∫–ª—é—á–∞–π –µ–≥–æ –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä—É\n"
        "- –ò—Å—Ç–æ—á–Ω–∏–∫ –¥–æ–±–∞–≤–ª—è–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏"
    )
    
    user_prompt = (
        f"–ù–∏–∂–µ —Å—ã—Ä–æ–π —Ç–µ–∫—Å—Ç –æ–¥–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã. –ü—Ä–µ–æ–±—Ä–∞–∑—É–π –µ–≥–æ –ø–æ –æ–ø–∏—Å–∞–Ω–∏—é.\n\n{dirty_text[:60000]}"
    )
    
    try:
        resp = ai_token_manager.make_openai_request(
            messages=[
                {"role": "system", "content": system_prompt.format(url=source_url)},
                {"role": "user", "content": user_prompt}
            ],
            model="gpt-4o-mini",
            user_id=user_id,
        )
        content = None
        # –ü—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –∏–∑ –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤ –æ—Ç–≤–µ—Ç–∞
        if resp and hasattr(resp, 'choices') and resp.choices:
            choice = resp.choices[0]
            if hasattr(choice, 'message') and hasattr(choice.message, 'content'):
                content = choice.message.content
        elif resp and isinstance(resp, dict):
            content = resp.get('content') or resp.get('text')
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫ –≤ –∫–æ–Ω–µ—Ü –µ—Å–ª–∏ GPT –µ–≥–æ –Ω–µ –¥–æ–±–∞–≤–∏–ª
        final_content = content or dirty_text
        if "## –ò—Å—Ç–æ—á–Ω–∏–∫–∏" not in final_content:
            final_content += f"\n\n## –ò—Å—Ç–æ—á–Ω–∏–∫–∏\n- {source_url}"
            
        return final_content
    except Exception as e:
        logger.warning(f"[CLEAN_SINGLE_PAGE] fallback to dirty text due to error: {e}")
        return f"{dirty_text}\n\n## –ò—Å—Ç–æ—á–Ω–∏–∫–∏\n- {source_url}"


def _clean_website_text_via_gpt(dirty_text: str, user_id: int) -> str:
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Å—ã—Ä–æ–π —Ç–µ–∫—Å—Ç –≤ GPT –¥–ª—è —É–ø–æ—Ä—è–¥–æ—á–∏–≤–∞–Ω–∏—è –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–∏—è."""
    system_prompt = (
        "–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–∏—é –∫–æ–Ω—Ç–µ–Ω—Ç–∞ —Å–∞–π—Ç–æ–≤ –¥–ª—è —Å–∏—Å—Ç–µ–º –∑–Ω–∞–Ω–∏–π. "
        "–ó–∞–¥–∞—á–∞: –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Å–∞–π—Ç–∞ –∏ —Å–æ–∑–¥–∞—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ Markdown.\n\n"
        
        "–ò–ù–°–¢–†–£–ö–¶–ò–ò –ü–û –ê–ù–ê–õ–ò–ó–£:\n"
        "1. –û–ø—Ä–µ–¥–µ–ª–∏ —Ç–∏–ø –±–∏–∑–Ω–µ—Å–∞/–æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ (–∫–æ–Ω—Å–∞–ª—Ç–∏–Ω–≥, e-commerce, —É—Å–ª—É–≥–∏, –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–æ, –±–ª–æ–≥, –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∏ —Ç.–¥.)\n"
        "2. –í—ã–¥–µ–ª–∏ –¢–û–õ–¨–ö–û —Ñ–∞–∫—Ç–∏—á–µ—Å–∫—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é, —É–±–µ—Ä–∏ –º–∞—Ä–∫–µ—Ç–∏–Ω–≥–æ–≤—É—é –≤–æ–¥—É –∏ –ø–æ–≤—Ç–æ—Ä—ã\n"
        "3. –°–æ—Ö—Ä–∞–Ω–∏ –≤–∞–∂–Ω—ã–µ –¥–µ—Ç–∞–ª–∏: —Ü–µ–Ω—ã, –∫–æ–Ω—Ç–∞–∫—Ç—ã, –ø—Ä–æ—Ü–µ—Å—Å—ã, —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏\n"
        "4. –£–¥–∞–ª–∏ —ç–ª–µ–º–µ–Ω—Ç—ã –Ω–∞–≤–∏–≥–∞—Ü–∏–∏, –∫–Ω–æ–ø–∫–∏, —Ñ–æ—Ä–º—ã, —Ñ—É—Ç–µ—Ä—ã\n\n"
        
        "–°–¢–†–£–ö–¢–£–†–ê –í–´–í–û–î–ê:\n"
        "–°–æ–∑–¥–∞–π –∞–¥–∞–ø—Ç–∏–≤–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–π–¥–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞. –ò—Å–ø–æ–ª—å–∑—É–π —ç—Ç–∏ —Ä–∞–∑–¥–µ–ª—ã, –µ—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –µ—Å—Ç—å:\n\n"
        "## –û—Å–Ω–æ–≤–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è\n"
        "- –ù–∞–∑–≤–∞–Ω–∏–µ –∫–æ–º–ø–∞–Ω–∏–∏/–ø—Ä–æ–µ–∫—Ç–∞\n"
        "- –ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏\n"
        "- –ö–ª—é—á–µ–≤—ã–µ —Ñ–∞–∫—Ç—ã (–≥–æ–¥–∞ —Ä–∞–±–æ—Ç—ã, –º–∞—Å—à—Ç–∞–±, –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è)\n\n"
        
        "## –ü—Ä–æ–¥—É–∫—Ç—ã/–£—Å–ª—É–≥–∏\n"
        "- –û—Å–Ω–æ–≤–Ω—ã–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è\n"
        "- –û–ø–∏—Å–∞–Ω–∏–µ –∫–∞–∂–¥–æ–≥–æ –ø—Ä–æ–¥—É–∫—Ç–∞/—É—Å–ª—É–≥–∏\n"
        "- –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ (–µ—Å–ª–∏ –µ—Å—Ç—å)\n\n"
        
        "## –ü—Ä–æ—Ü–µ—Å—Å—ã –∏ –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏—è\n"
        "- –≠—Ç–∞–ø—ã —Ä–∞–±–æ—Ç—ã\n"
        "- –ü–æ–¥—Ö–æ–¥—ã –∏ –º–µ—Ç–æ–¥—ã\n"
        "- –í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä–∞–º–∫–∏\n\n"
        
        "## –¶–µ–ª–µ–≤–∞—è –∞—É–¥–∏—Ç–æ—Ä–∏—è\n"
        "- –°–µ–≥–º–µ–Ω—Ç—ã –∫–ª–∏–µ–Ω—Ç–æ–≤\n"
        "- –°–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ –æ—Ç—Ä–∞—Å–ª—è–º\n\n"
        
        "## –¶–µ–Ω–æ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ\n"
        "- –¢–∞—Ä–∏—Ñ–Ω—ã–µ –ø–ª–∞–Ω—ã\n"
        "- –°—Ç–æ–∏–º–æ—Å—Ç—å —É—Å–ª—É–≥\n"
        "- –£—Å–ª–æ–≤–∏—è –æ–ø–ª–∞—Ç—ã\n\n"
        
        "## –ö–æ–Ω—Ç–∞–∫—Ç–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è\n"
        "- –¢–µ–ª–µ—Ñ–æ–Ω—ã\n"
        "- Email –∞–¥—Ä–µ—Å–∞\n"
        "- –ú–µ—Å—Å–µ–Ω–¥–∂–µ—Ä—ã (Telegram, WhatsApp)\n"
        "- –§–∏–∑–∏—á–µ—Å–∫–∏–π –∞–¥—Ä–µ—Å\n"
        "- –°–æ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–µ—Ç–∏\n\n"
        
        "## –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è\n"
        "- FAQ\n"
        "- –û—Ç–∑—ã–≤—ã –∫–ª–∏–µ–Ω—Ç–æ–≤\n"
        "- –ü–æ—Ä—Ç—Ñ–æ–ª–∏–æ/–∫–µ–π—Å—ã\n"
        "- –°–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç—ã/–Ω–∞–≥—Ä–∞–¥—ã\n\n"
        
        "–ü–†–ê–í–ò–õ–ê:\n"
        "- –ù–ï –∏—Å–ø–æ–ª—å–∑—É–π —Ä–∞–∑–¥–µ–ª—ã, –µ—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ—Ç\n"
        "- –ù–ï –≤—ã–¥—É–º—ã–≤–∞–π –¥–∞–Ω–Ω—ã–µ\n"
        "- –°–æ—Ö—Ä–∞–Ω—è–π —Ç–æ—á–Ω—ã–µ —Ü–∏—Ñ—Ä—ã, –¥–∞—Ç—ã, –∏–º–µ–Ω–∞\n"
        "- –£–±–∏—Ä–∞–π –¥—É–±–ª–∏—Ä—É—é—â—É—é—Å—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é\n"
        "- –ò—Å–ø–æ–ª—å–∑—É–π —Å–ø–∏—Å–∫–∏ –¥–ª—è –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–∏–π\n"
        "- –í –∫–æ–Ω—Ü–µ –¥–æ–±–∞–≤—å —Ä–∞–∑–¥–µ–ª '## –ò—Å—Ç–æ—á–Ω–∏–∫' —Å –∏—Å—Ö–æ–¥–Ω—ã–º URL"
    )
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∞–Ω–∞–ª–∏–∑ —Ç–∏–ø–∞ —Å–∞–π—Ç–∞ –¥–ª—è –±–æ–ª–µ–µ —Ç–æ—á–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–∏–∑–∞—Ü–∏–∏
    site_analysis = _analyze_website_type(dirty_text[:5000])
    
    user_prompt = (
        f"–ù–∏–∂–µ —Å—ã—Ä–æ–π —Ç–µ–∫—Å—Ç, –ø–æ–ª—É—á–µ–Ω–Ω—ã–π –ø–æ—Å–ª–µ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å–∞–π—Ç–∞.\n"
        f"–ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç: {site_analysis}\n"
        f"–ü—Ä–µ–æ–±—Ä–∞–∑—É–π –µ–≥–æ –ø–æ –æ–ø–∏—Å–∞–Ω–∏—é, –∞–¥–∞–ø—Ç–∏—Ä—É—è —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–æ–¥ —Ç–∏–ø –±–∏–∑–Ω–µ—Å–∞.\n\n"
        + dirty_text[:120000]
    )
    try:
        resp = ai_token_manager.make_openai_request(
            messages=[{"role": "system", "content": system_prompt}, {"role": "user", "content": user_prompt}],
            model="gpt-4o-mini",
            user_id=user_id,
        )
        content = None
        # –ü—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –∏–∑ –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤ –æ—Ç–≤–µ—Ç–∞
        if resp and hasattr(resp, 'choices') and resp.choices:
            choice = resp.choices[0]
            if hasattr(choice, 'message') and hasattr(choice.message, 'content'):
                content = choice.message.content
        elif resp and isinstance(resp, dict):
            content = resp.get('content') or resp.get('text')
        return content or dirty_text
    except Exception as e:
        logger.warning(f"[CLEAN_WEBSITE] fallback to dirty text due to error: {e}")
        return dirty_text


def _analyze_website_type(text_sample: str) -> str:
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç–∏–ø —Å–∞–π—Ç–∞ –ø–æ –æ–±—Ä–∞–∑—Ü—É —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –ª—É—á—à–µ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–∏–∑–∞—Ü–∏–∏."""
    text_lower = text_sample.lower()
    
    # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –±–∏–∑–Ω–µ—Å–∞
    keywords = {
        '–∫–æ–Ω—Å–∞–ª—Ç–∏–Ω–≥': ['–∫–æ–Ω—Å–∞–ª—Ç–∏–Ω–≥', '–∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–∏', '–±–∏–∑–Ω–µ—Å-–ø—Ä–æ—Ü–µ—Å—Å', '—Å—Ç—Ä–∞—Ç–µ–≥–∏—è', '—É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ', '–∞–Ω–∞–ª–∏–∑', '–∞—É–¥–∏—Ç'],
        'e-commerce/–º–∞–≥–∞–∑–∏–Ω': ['–∫—É–ø–∏—Ç—å', '–∑–∞–∫–∞–∑–∞—Ç—å', '—Ç–æ–≤–∞—Ä', '—Ü–µ–Ω–∞', '–¥–æ—Å—Ç–∞–≤–∫–∞', '–∫–æ—Ä–∑–∏–Ω–∞', '–∫–∞—Ç–∞–ª–æ–≥', '—Å–∫–∏–¥–∫–∞'],
        '—É—Å–ª—É–≥–∏': ['—É—Å–ª—É–≥–∏', '—Å–µ—Ä–≤–∏—Å', '–æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ', '—Ä–µ–º–æ–Ω—Ç', '—É—Å—Ç–∞–Ω–æ–≤–∫–∞', '—Å–æ–ø—Ä–æ–≤–æ–∂–¥–µ–Ω–∏–µ'],
        '–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ': ['–∫—É—Ä—Å', '–æ–±—É—á–µ–Ω–∏–µ', '—Ç—Ä–µ–Ω–∏–Ω–≥', '–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ', '—É—Ä–æ–∫', '–ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—å', '—Å—Ç—É–¥–µ–Ω—Ç'],
        '–ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–æ': ['–ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–æ', '–∏–∑–≥–æ—Ç–æ–≤–ª–µ–Ω–∏–µ', '–∑–∞–≤–æ–¥', '—Ñ–∞–±—Ä–∏–∫–∞', '–æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ', '—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è'],
        'IT/—Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞': ['—Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞', '–ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ', '–≤–µ–±', '—Å–∞–π—Ç', '–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ', '—Å–æ—Ñ—Ç', 'it'],
        '–º–µ–¥–∏—Ü–∏–Ω–∞': ['–∫–ª–∏–Ω–∏–∫–∞', '–≤—Ä–∞—á', '–ª–µ—á–µ–Ω–∏–µ', '–¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞', '–º–µ–¥–∏—Ü–∏–Ω–∞', '–∑–¥–æ—Ä–æ–≤—å–µ', '–ø–∞—Ü–∏–µ–Ω—Ç'],
        '–Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç—å': ['–Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç—å', '–∫–≤–∞—Ä—Ç–∏—Ä–∞', '–¥–æ–º', '–∞—Ä–µ–Ω–¥–∞', '–ø—Ä–æ–¥–∞–∂–∞', '—Ä–∏—ç–ª—Ç–æ—Ä', '–∏–ø–æ—Ç–µ–∫–∞'],
        '—Ñ–∏–Ω–∞–Ω—Å—ã': ['–±–∞–Ω–∫', '–∫—Ä–µ–¥–∏—Ç', '–∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏', '—Å—Ç—Ä–∞—Ö–æ–≤–∞–Ω–∏–µ', '–∑–∞–π–º', '—Ñ–∏–Ω–∞–Ω—Å—ã', '–¥–µ–Ω—å–≥–∏'],
        '–±–ª–æ–≥/–º–µ–¥–∏–∞': ['—Å—Ç–∞—Ç—å—è', '–Ω–æ–≤–æ—Å—Ç–∏', '–±–ª–æ–≥', '–∂—É—Ä–Ω–∞–ª', '–ø—É–±–ª–∏–∫–∞—Ü–∏—è', '—Ä–µ–¥–∞–∫—Ü–∏—è', '–∞–≤—Ç–æ—Ä']
    }
    
    # –ü–æ–¥—Å—á–µ—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π
    scores = {}
    for category, words in keywords.items():
        score = sum(1 for word in words if word in text_lower)
        if score > 0:
            scores[category] = score
    
    if not scores:
        return "—É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã–π —Å–∞–π—Ç"
    
    # –ù–∞—Ö–æ–¥–∏–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–º —Å–∫–æ—Ä–æ–º
    best_category = max(scores, key=scores.get)
    confidence = scores[best_category]
    
    if confidence >= 3:
        return f"—Å–∞–π—Ç –≤ —Å—Ñ–µ—Ä–µ '{best_category}' (–≤—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å)"
    elif confidence >= 2:
        return f"—Å–∞–π—Ç –≤ —Å—Ñ–µ—Ä–µ '{best_category}' (—Å—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å)"
    else:
        return f"–≤–æ–∑–º–æ–∂–Ω–æ, —Å–∞–π—Ç –≤ —Å—Ñ–µ—Ä–µ '{best_category}' (–Ω–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å)"


@router.post("/assistants/{assistant_id}/validate-knowledge")
def validate_assistant_knowledge(
    assistant_id: int,
    current_user: models.User = Depends(auth.get_current_user),
    db: Session = Depends(get_db)
):
    """–í–∞–ª–∏–¥–∏—Ä—É–µ—Ç –∏ –æ—á–∏—â–∞–µ—Ç –∑–Ω–∞–Ω–∏—è –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –æ—Ç fallback –¥–∞–Ω–Ω—ã—Ö"""
    from utils.knowledge_validator import create_knowledge_validator
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–∞–≤–∞ –¥–æ—Å—Ç—É–ø–∞
    assistant = db.query(models.Assistant).filter(
        models.Assistant.id == assistant_id,
        models.Assistant.user_id == current_user.id
    ).first()
    
    if not assistant:
        raise HTTPException(status_code=404, detail="Assistant not found")
    
    # –°–æ–∑–¥–∞–µ–º –≤–∞–ª–∏–¥–∞—Ç–æ—Ä –∏ –æ—á–∏—â–∞–µ–º –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞
    validator = create_knowledge_validator(db)
    
    # –ü–æ–ª—É—á–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –¥–æ –æ—á–∏—Å—Ç–∫–∏
    validation_before = validator.validate_assistant_knowledge(assistant_id, current_user.id)
    
    # –í—ã–ø–æ–ª–Ω—è–µ–º –æ—á–∏—Å—Ç–∫—É
    is_clean = validator.ensure_clean_assistant(assistant_id, current_user.id)
    
    # –ü–æ–ª—É—á–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏
    validation_after = validator.validate_assistant_knowledge(assistant_id, current_user.id)
    
    # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –∫—ç—à–µ–π
    try:
        from utils.bot_cleanup import full_bot_cleanup
        full_bot_cleanup(current_user.id, assistant_id, db)
    except Exception as e:
        logger.warning(f"–û—à–∏–±–∫–∞ –ø–æ–ª–Ω–æ–π –æ—á–∏—Å—Ç–∫–∏: {e}")
    
    return {
        "assistant_id": assistant_id,
        "is_clean": is_clean,
        "validation_before": validation_before,
        "validation_after": validation_after,
        "changes": {
            "knowledge_removed": validation_before['knowledge_count'] - validation_after['knowledge_count'],
            "fallback_sources_removed": validation_before['has_fallback_sources'] and not validation_after['has_fallback_sources']
        }
    }


@router.get("/assistants/{assistant_id}/knowledge")
def get_assistant_knowledge(assistant_id: int, current_user: models.User = Depends(auth.get_current_user), db: Session = Depends(get_db)):
    """–ü–æ–ª—É—á–∏—Ç—å –∑–Ω–∞–Ω–∏—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞"""
    assistant = db.query(models.Assistant).filter(
        models.Assistant.id == assistant_id,
        models.Assistant.user_id == current_user.id
    ).first()
    
    if not assistant:
        raise HTTPException(status_code=404, detail="Assistant not found")
    
    # –ü–æ–ª—É—á–∞–µ–º –¢–û–õ–¨–ö–û –∑–Ω–∞–Ω–∏—è, –ø—Ä–∏–≤—è–∑–∞–Ω–Ω—ã–µ –∫ —ç—Ç–æ–º—É –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç—É
    # –ù–ï –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback –∫ –æ–±—â–∏–º –∑–Ω–∞–Ω–∏—è–º - –∫–∞–∂–¥—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —É–Ω–∏–∫–∞–ª—å–Ω—ã–º
    knowledge_with_docs = db.query(
        models.UserKnowledge,
        models.Document
    ).join(
        models.Document, 
        models.UserKnowledge.doc_id == models.Document.id
    ).filter(
        models.UserKnowledge.user_id == current_user.id,
        models.UserKnowledge.assistant_id == assistant_id  # –¢–û–õ–¨–ö–û —ç—Ç–æ–≥–æ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞
    ).all()
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã —Ç–æ–ª—å–∫–æ –∏–∑ –∑–Ω–∞–Ω–∏–π —ç—Ç–æ–≥–æ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞
    documents = []
    for entry, doc in knowledge_with_docs:
        doc_type = entry.doc_type or "–î–æ–∫—É–º–µ–Ω—Ç"
        
        if doc.filename.startswith('quick_fix_'):
            documents.append(entry.content)
        else:
            prefix = f"–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞ —Ç–∏–ø–∞ '{doc_type}':\n"
            documents.append(prefix + entry.content)
    
    return {
        "assistant_id": assistant_id,
        "system_prompt": assistant.system_prompt,
        "documents": documents  # –ë—É–¥–µ—Ç –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ –¥–ª—è –Ω–æ–≤–æ–≥–æ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞
    }

# --- Assistant Documents ---

@router.get("/assistants/{assistant_id}/documents", response_model=TypingList[schemas.DocumentRead])
def list_assistant_documents(
    assistant_id: int,
    current_user: models.User = Depends(auth.get_current_user),
    db: Session = Depends(get_db)
):
    """
    Optimized assistant documents endpoint - uses single query with joins to avoid N+1
    """
    logger.debug(f"[API] Fetching documents for assistant {assistant_id}")
    
    # First verify assistant ownership
    assistant = db.query(models.Assistant).filter(
        models.Assistant.id == assistant_id,
        models.Assistant.user_id == current_user.id
    ).first()
    if not assistant:
        raise HTTPException(status_code=404, detail="Assistant not found")

    # Optimized single query with joins and eager loading
    documents = db.query(models.Document)\
        .options(
            joinedload(models.Document.user),
            selectinload(models.Document.knowledge)
        )\
        .join(models.UserKnowledge, models.Document.id == models.UserKnowledge.doc_id)\
        .filter(
            models.Document.user_id == current_user.id,
            models.UserKnowledge.assistant_id == assistant_id
        )\
        .distinct()\
        .order_by(models.Document.upload_date.desc())\
        .all()

    logger.debug(f"[API] Retrieved {len(documents)} documents for assistant {assistant_id} with optimized query")
    return documents

@router.get("/assistants/{assistant_id}/dialogs")
def list_assistant_dialogs(
    assistant_id: int,
    current_user: models.User = Depends(auth.get_current_user),
    db: Session = Depends(get_db)
):
    """
    Optimized assistant dialogs endpoint - uses single query with aggregations to avoid N+1
    """
    logger.debug(f"[API] Fetching dialogs for assistant {assistant_id}")
    
    assistant = db.query(models.Assistant).filter(
        models.Assistant.id == assistant_id,
        models.Assistant.user_id == current_user.id
    ).first()
    if not assistant:
        raise HTTPException(status_code=404, detail="Assistant not found")

    # Optimized single query with aggregations and eager loading
    dialogs_query = db.query(
        models.Dialog,
        func.count(models.DialogMessage.id).label('message_count'),
        func.max(models.DialogMessage.timestamp).label('last_message_at')
    )\
    .options(
        joinedload(models.Dialog.user),
        joinedload(models.Dialog.assistant)
    )\
    .outerjoin(models.DialogMessage)\
    .filter(
        models.Dialog.user_id == current_user.id,
        models.Dialog.assistant_id == assistant_id
    )\
    .group_by(models.Dialog.id)\
    .order_by(models.Dialog.started_at.desc())\
    .all()

    dialogs_data = []
    for dialog, message_count, last_message_at in dialogs_query:
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–∏–∞–ª–æ–≥–∞
        if dialog.first_name:
            title = f"–î–∏–∞–ª–æ–≥ —Å {dialog.first_name}"
            if dialog.last_name:
                title += f" {dialog.last_name}"
        elif dialog.telegram_username:
            title = f"–î–∏–∞–ª–æ–≥ —Å @{dialog.telegram_username}"
        else:
            title = f"–î–∏–∞–ª–æ–≥ {dialog.id}"
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ç–∞—Ç—É—Å
        status = "completed" if dialog.ended_at else "active"
        
        dialogs_data.append({
            "id": dialog.id,
            "title": title,
            "status": status,
            "started_at": dialog.started_at.isoformat() if dialog.started_at else None,
            "last_message_at": last_message_at.isoformat() if last_message_at else None,
            "message_count": message_count or 0
        })
    
    return dialogs_data

@router.post("/assistants/{assistant_id}/documents", response_model=schemas.DocumentRead)
async def upload_assistant_document(
    assistant_id: int,
    file: UploadFile = File(...),
    current_user: models.User = Depends(auth.get_current_user),
    db: Session = Depends(get_db)
):
    """–ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç –∏ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞—Ç—å –µ–≥–æ –¢–û–õ–¨–ö–û –ø–æ–¥ —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞"""
    from .documents import upload_document
    # –ü–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ —Å –ø–µ—Ä–µ–¥–∞—á–µ–π assistant_id
    return await upload_document(file=file, assistant_id=assistant_id, current_user=current_user, db=db)



# --- User Assistant Lookup (for bots) ---

@router.get("/user-telegram-assistant/{user_id}")
def get_user_telegram_assistant(user_id: int, db: Session = Depends(get_db)):
    """–ü–æ–ª—É—á–∏—Ç—å –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –ø—Ä–∏–≤—è–∑–∞–Ω–Ω–æ–≥–æ –∫ Telegram –±–æ—Ç—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    bot_instance = db.query(models.BotInstance).filter(
        models.BotInstance.user_id == user_id,
        models.BotInstance.platform == 'telegram',
        models.BotInstance.is_active == True
    ).first()
    
    if not bot_instance:
        return None
        
    assistant = db.query(models.Assistant).filter(
        models.Assistant.id == bot_instance.assistant_id
    ).first()
    
    if not assistant:
        return None
        
    return {
        "id": assistant.id,
        "name": assistant.name,
        "system_prompt": assistant.system_prompt,
        "is_active": assistant.is_active
    }


@router.get("/assistants/stats")
def get_assistants_stats(db: Session = Depends(get_db), current_user: models.User = Depends(auth.get_current_user)):
    """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –≤—Å–µ–º –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    effective_user_id = auth.get_effective_user_id(current_user, db)
    
    # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    assistants = crud.get_assistants(db, effective_user_id)
    
    # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    total_assistants = len(assistants)
    active_assistants = len([a for a in assistants if a.is_active])
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Å–æ–æ–±—â–µ–Ω–∏—è–º –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π –º–µ—Å—è—Ü
    from datetime import datetime, timedelta
    now = datetime.utcnow()
    month_ago = now - timedelta(days=30)
    
    total_messages = 0
    total_dialogs = 0
    assistant_stats = []
    
    for assistant in assistants:
        # –ü–æ–¥—Å—á–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞
        messages_count = db.query(func.count(models.DialogMessage.id)).join(
            models.Dialog
        ).filter(
            models.Dialog.user_id == effective_user_id,
            models.Dialog.assistant_id == assistant.id,
            models.DialogMessage.sender == 'assistant',
            models.DialogMessage.timestamp >= month_ago
        ).scalar() or 0
        
        # –ü–æ–¥—Å—á–µ—Ç –¥–∏–∞–ª–æ–≥–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞
        dialogs_count = db.query(func.count(models.Dialog.id)).filter(
            models.Dialog.user_id == effective_user_id,
            models.Dialog.assistant_id == assistant.id,
            models.Dialog.started_at >= month_ago
        ).scalar() or 0
        
        total_messages += messages_count
        total_dialogs += dialogs_count
        
        assistant_stats.append({
            "id": assistant.id,
            "name": assistant.name,
            "messages": messages_count,
            "dialogs": dialogs_count,
            "is_active": assistant.is_active
        })
    
    return {
        "global": {
            "totalAssistants": total_assistants,
            "activeAssistants": active_assistants,
            "totalMessages": total_messages,
            "totalDialogs": total_dialogs
        },
        "byAssistant": assistant_stats
    }


@router.get("/assistants/{assistant_id}/stats")
def get_assistant_stats(
    assistant_id: int,
    db: Session = Depends(get_db),
    current_user: models.User = Depends(auth.get_current_user)
):
    """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞"""
    effective_user_id = auth.get_effective_user_id(current_user, db)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∏—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
    assistant = db.query(models.Assistant).filter(
        models.Assistant.id == assistant_id,
        models.Assistant.user_id == effective_user_id
    ).first()
    
    if not assistant:
        raise HTTPException(status_code=404, detail="Assistant not found")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Å–æ–æ–±—â–µ–Ω–∏—è–º –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π –º–µ—Å—è—Ü
    from datetime import datetime, timedelta
    now = datetime.utcnow()
    month_ago = now - timedelta(days=30)
    week_ago = now - timedelta(days=7)
    
    # –û–±—â–∏–µ —Å—á–µ—Ç—á–∏–∫–∏
    total_messages = db.query(func.count(models.DialogMessage.id)).join(
        models.Dialog
    ).filter(
        models.Dialog.user_id == effective_user_id,
        models.Dialog.assistant_id == assistant_id,
        models.DialogMessage.sender == 'assistant'
    ).scalar() or 0
    
    total_dialogs = db.query(func.count(models.Dialog.id)).filter(
        models.Dialog.user_id == effective_user_id,
        models.Dialog.assistant_id == assistant_id
    ).scalar() or 0
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∑–∞ –º–µ—Å—è—Ü
    monthly_messages = db.query(func.count(models.DialogMessage.id)).join(
        models.Dialog
    ).filter(
        models.Dialog.user_id == effective_user_id,
        models.Dialog.assistant_id == assistant_id,
        models.DialogMessage.sender == 'assistant',
        models.DialogMessage.timestamp >= month_ago
    ).scalar() or 0
    
    monthly_dialogs = db.query(func.count(models.Dialog.id)).filter(
        models.Dialog.user_id == effective_user_id,
        models.Dialog.assistant_id == assistant_id,
        models.Dialog.started_at >= month_ago
    ).scalar() or 0
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∑–∞ –Ω–µ–¥–µ–ª—é
    weekly_messages = db.query(func.count(models.DialogMessage.id)).join(
        models.Dialog
    ).filter(
        models.Dialog.user_id == effective_user_id,
        models.Dialog.assistant_id == assistant_id,
        models.DialogMessage.sender == 'assistant',
        models.DialogMessage.timestamp >= week_ago
    ).scalar() or 0
    
    weekly_dialogs = db.query(func.count(models.Dialog.id)).filter(
        models.Dialog.user_id == effective_user_id,
        models.Dialog.assistant_id == assistant_id,
        models.Dialog.started_at >= week_ago
    ).scalar() or 0
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º
    documents_count = db.query(func.count(models.Document.id.distinct())).join(
        models.UserKnowledge, models.Document.id == models.UserKnowledge.doc_id
    ).filter(
        models.UserKnowledge.user_id == effective_user_id,
        models.UserKnowledge.assistant_id == assistant_id
    ).scalar() or 0
    
    return {
        "assistant": {
            "id": assistant.id,
            "name": assistant.name,
            "is_active": assistant.is_active,
            "created_at": assistant.created_at.isoformat() if assistant.created_at else None
        },
        "stats": {
            "total_messages": total_messages,
            "total_dialogs": total_dialogs,
            "total_documents": documents_count,
            "monthly": {
                "messages": monthly_messages,
                "dialogs": monthly_dialogs
            },
            "weekly": {
                "messages": weekly_messages,
                "dialogs": weekly_dialogs
            }
        }
    }