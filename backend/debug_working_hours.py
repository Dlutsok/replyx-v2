#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏: –æ—Ç–∫—É–¥–∞ –±–æ—Ç –≤–∑—è–ª –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≤—Ä–µ–º–µ–Ω–∏ —Ä–∞–±–æ—Ç—ã
"""

from database.connection import SessionLocal
from database import models
from services.embeddings_service import embeddings_service
from sqlalchemy import func
import json

def debug_working_hours_source():
    """–î–∏–∞–≥–Ω–æ—Å—Ç–∏—Ä—É–µ—Ç –∏—Å—Ç–æ—á–Ω–∏–∫ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –≤—Ä–µ–º–µ–Ω–∏ —Ä–∞–±–æ—Ç—ã"""
    
    db = SessionLocal()
    
    try:
        print("üîç –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê –ò–°–¢–û–ß–ù–ò–ö–ê –ò–ù–§–û–†–ú–ê–¶–ò–ò –û –í–†–ï–ú–ï–ù–ò –†–ê–ë–û–¢–´")
        print("=" * 60)
        
        # 1. –ò—â–µ–º –≤—Å–µ—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π —Å –±–æ—Ç–∞–º–∏
        users_with_bots = db.query(models.User).join(models.Assistant).all()
        
        if not users_with_bots:
            print("‚ùå –ù–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π —Å –±–æ—Ç–∞–º–∏")
            return
            
        for user in users_with_bots:
            print(f"\nüë§ –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–¨: {user.email} (ID: {user.id})")
            
            # –ü–æ–ª—É—á–∞–µ–º –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            assistants = db.query(models.Assistant).filter(
                models.Assistant.user_id == user.id
            ).all()
            
            for assistant in assistants:
                print(f"\nü§ñ –ê–°–°–ò–°–¢–ï–ù–¢: {assistant.name} (ID: {assistant.id})")
                
                # 2. –ü—Ä–æ–≤–µ—Ä—è–µ–º UserKnowledge
                knowledge_entries = db.query(models.UserKnowledge).filter(
                    models.UserKnowledge.user_id == user.id,
                    models.UserKnowledge.assistant_id == assistant.id
                ).all()
                
                print(f"üìö –ù–∞–π–¥–µ–Ω–æ {len(knowledge_entries)} –∑–∞–ø–∏—Å–µ–π –∑–Ω–∞–Ω–∏–π")
                
                working_hours_found = False
                
                for entry in knowledge_entries:
                    content_lower = entry.content.lower()
                    if any(phrase in content_lower for phrase in [
                        '–≤—Ä–µ–º—è —Ä–∞–±–æ—Ç—ã', '–ø–Ω-–ø—Ç', '–ø–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫', '–≤—Ç–æ—Ä–Ω–∏–∫', 
                        '09:00', '18:00', '—Ä–∞–±–æ—á–∏–µ —á–∞—Å—ã', '–≥—Ä–∞—Ñ–∏–∫ —Ä–∞–±–æ—Ç—ã'
                    ]):
                        working_hours_found = True
                        print(f"\n‚úÖ –ù–ê–ô–î–ï–ù–ê –ò–ù–§–û–†–ú–ê–¶–ò–Ø –û –í–†–ï–ú–ï–ù–ò –†–ê–ë–û–¢–´:")
                        print(f"   üìÑ –î–æ–∫—É–º–µ–Ω—Ç ID: {entry.doc_id}")
                        print(f"   üìù –¢–∏–ø: {entry.doc_type}")
                        print(f"   üìä –í–∞–∂–Ω–æ—Å—Ç—å: {entry.importance}")
                        print(f"   üìÖ –°–æ–∑–¥–∞–Ω–æ: {entry.created_at}")
                        print(f"   üìã –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ (–ø–µ—Ä–≤—ã–µ 300 —Å–∏–º–≤–æ–ª–æ–≤):")
                        print(f"   {entry.content[:300]}...")
                        
                        # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–æ–∫—É–º–µ–Ω—Ç–µ
                        doc = db.query(models.Document).filter(
                            models.Document.id == entry.doc_id
                        ).first()
                        
                        if doc:
                            print(f"   üìé –§–∞–π–ª: {doc.filename}")
                            print(f"   üìÖ –ó–∞–≥—Ä—É–∂–µ–Ω: {doc.upload_date}")
                
                # 3. –ü—Ä–æ–≤–µ—Ä—è–µ–º embeddings
                embeddings_count = db.query(models.KnowledgeEmbedding).filter(
                    models.KnowledgeEmbedding.user_id == user.id,
                    models.KnowledgeEmbedding.assistant_id == assistant.id
                ).count()
                
                print(f"üß† –ù–∞–π–¥–µ–Ω–æ {embeddings_count} embeddings")
                
                # 4. –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–∏—Å–∫ –ø–æ –∑–∞–ø—Ä–æ—Å—É "–≤—Ä–µ–º—è —Ä–∞–±–æ—Ç—ã"
                print(f"\nüîç –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ü–û–ò–°–ö–ê –ü–û –ó–ê–ü–†–û–°–£ '–≤—Ä–µ–º—è —Ä–∞–±–æ—Ç—ã':")
                
                relevant_chunks = embeddings_service.search_relevant_chunks(
                    query="–≤—Ä–µ–º—è —Ä–∞–±–æ—Ç—ã",
                    user_id=user.id,
                    assistant_id=assistant.id,
                    top_k=3,
                    min_similarity=0.5,  # –ü–æ–Ω–∏–∂–∞–µ–º –ø–æ—Ä–æ–≥ –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
                    db=db
                )
                
                print(f"   –ù–∞–π–¥–µ–Ω–æ {len(relevant_chunks)} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —á–∞–Ω–∫–æ–≤:")
                
                for i, chunk in enumerate(relevant_chunks, 1):
                    print(f"\n   {i}. –°—Ö–æ–∂–µ—Å—Ç—å: {chunk['similarity']:.3f}")
                    print(f"      –¢–∏–ø: {chunk['doc_type']}")
                    print(f"      –í–∞–∂–Ω–æ—Å—Ç—å: {chunk['importance']}")
                    print(f"      –¢–µ–∫—Å—Ç (–ø–µ—Ä–≤—ã–µ 200 —Å–∏–º–≤–æ–ª–æ–≤):")
                    print(f"      {chunk['text'][:200]}...")
                
                if not working_hours_found and not relevant_chunks:
                    print("‚ùå –ù–ï –ù–ê–ô–î–ï–ù–û –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –≤—Ä–µ–º–µ–Ω–∏ —Ä–∞–±–æ—Ç—ã –≤ –∑–Ω–∞–Ω–∏—è—Ö")
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –º–æ–∂–µ—Ç –ª–∏ –ò–ò –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç –±–µ–∑ –∑–Ω–∞–Ω–∏–π
                    print("\n‚ö†Ô∏è  –í–û–ó–ú–û–ñ–ù–´–ï –ò–°–¢–û–ß–ù–ò–ö–ò:")
                    print("   1. –ò–ò –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–±—â–∏—Ö –∑–Ω–∞–Ω–∏–π")
                    print("   2. –ï—Å—Ç—å fallback –≤ –∫–æ–¥–µ –Ω–∞ —Å—Ç–∞—Ä—É—é —Å–∏—Å—Ç–µ–º—É –∑–Ω–∞–Ω–∏–π")
                    print("   3. –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –±–µ—Ä–µ—Ç—Å—è –∏–∑ —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞")
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
                    if assistant.system_prompt:
                        prompt_lower = assistant.system_prompt.lower()
                        if any(phrase in prompt_lower for phrase in [
                            '–≤—Ä–µ–º—è —Ä–∞–±–æ—Ç—ã', '–ø–Ω-–ø—Ç', '09:00', '18:00'
                        ]):
                            print("   ‚úÖ –ù–ê–ô–î–ï–ù–û –≤ —Å–∏—Å—Ç–µ–º–Ω–æ–º –ø—Ä–æ–º–ø—Ç–µ!")
                            print(f"      –ü—Ä–æ–º–ø—Ç: {assistant.system_prompt[:200]}...")
                
                print("\n" + "-" * 50)
        
        # 5. –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—â–∏–µ –∑–Ω–∞–Ω–∏—è (–±–µ–∑ –ø—Ä–∏–≤—è–∑–∫–∏ –∫ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç—É)
        print(f"\nüåê –ü–†–û–í–ï–†–ö–ê –û–ë–©–ò–• –ó–ù–ê–ù–ò–ô (–±–µ–∑ –ø—Ä–∏–≤—è–∑–∫–∏ –∫ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç—É):")
        
        general_knowledge = db.query(models.UserKnowledge).filter(
            models.UserKnowledge.assistant_id.is_(None)
        ).all()
        
        print(f"–ù–∞–π–¥–µ–Ω–æ {len(general_knowledge)} –æ–±—â–∏—Ö –∑–∞–ø–∏—Å–µ–π –∑–Ω–∞–Ω–∏–π")
        
        for entry in general_knowledge:
            content_lower = entry.content.lower()
            if any(phrase in content_lower for phrase in [
                '–≤—Ä–µ–º—è —Ä–∞–±–æ—Ç—ã', '–ø–Ω-–ø—Ç', '09:00', '18:00'
            ]):
                print(f"‚úÖ –ù–ê–ô–î–ï–ù–ê –æ–±—â–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –≤—Ä–µ–º–µ–Ω–∏ —Ä–∞–±–æ—Ç—ã:")
                print(f"   –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å ID: {entry.user_id}")
                print(f"   –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ: {entry.content[:300]}...")
        
    except Exception as e:
        print(f"‚ùå –û–®–ò–ë–ö–ê: {e}")
        import traceback
        traceback.print_exc()
        
    finally:
        db.close()

if __name__ == "__main__":
    debug_working_hours_source()