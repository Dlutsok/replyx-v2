#!/usr/bin/env python3
"""
üìä –ú–û–ù–ò–¢–û–†–ò–ù–ì –†–ê–ó–ú–ï–†–ê –ë–ê–ó–´ –î–ê–ù–ù–´–• ChatAI
–û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ —Ä–æ—Å—Ç–∞ –ë–î, —Ä–∞–∑–º–µ—Ä–æ–≤ —Ç–∞–±–ª–∏—Ü, —Å–≤–æ–±–æ–¥–Ω–æ–≥–æ –º–µ—Å—Ç–∞ –Ω–∞ –¥–∏—Å–∫–µ
–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –∞–ª–µ—Ä—Ç—ã –ø—Ä–∏ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –ø–æ–∫–∞–∑–∞—Ç–µ–ª—è—Ö
"""

import os
import sys
import time
import logging
import psutil
import json
import smtplib
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple
from sqlalchemy import text, func
from sqlalchemy.orm import Session
from sqlalchemy.engine import Engine
from pathlib import Path
try:
    from email.mime.text import MimeText
    from email.mime.multipart import MimeMultipart
except ImportError:
    # Fallback –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
    MimeText = None
    MimeMultipart = None

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –∫–æ—Ä–Ω—é –ø—Ä–æ–µ–∫—Ç–∞ –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞ –º–æ–¥—É–ª–µ–π
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from database.connection import get_db
from monitoring.audit_logger import audit_log
from core.app_config import *

logger = logging.getLogger(__name__)


class DatabaseSizeMonitor:
    """–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Ä–∞–∑–º–µ—Ä–∞ –ë–î –∏ –¥–∏—Å–∫–æ–≤–æ–≥–æ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞"""
    
    def __init__(self):
        self.thresholds = {
            'db_size_gb': float(os.getenv('DB_SIZE_THRESHOLD_GB', '10')),  # 10GB
            'table_size_gb': float(os.getenv('TABLE_SIZE_THRESHOLD_GB', '1')),  # 1GB
            'disk_usage_percent': float(os.getenv('DB_DISK_USAGE_THRESHOLD', '0.85')),  # 85%
            'growth_rate_mb_day': float(os.getenv('DB_GROWTH_THRESHOLD_MB_DAY', '100'))  # 100MB/–¥–µ–Ω—å
        }
        
        self.email_alerts = os.getenv('DB_MONITOR_EMAIL_ALERTS', 'false').lower() == 'true'
        self.alert_emails = os.getenv('DB_MONITOR_ALERT_EMAILS', '').split(',')
        
        # –§–∞–π–ª –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –∏—Å—Ç–æ—Ä–∏–∏ —Ä–∞–∑–º–µ—Ä–æ–≤
        self.history_file = Path('data/db_size_history.json')
        self.history_file.parent.mkdir(exist_ok=True)
        
    def get_database_size_info(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∞–µ—Ç –ø–æ–¥—Ä–æ–±–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ä–∞–∑–º–µ—Ä–∞—Ö –ë–î"""
        try:
            db = next(get_db())
            try:
                # –û–±—â–∏–π —Ä–∞–∑–º–µ—Ä –ë–î
                db_info = db.execute(text("""
                    SELECT 
                        pg_database_size(current_database()) as size_bytes,
                        pg_size_pretty(pg_database_size(current_database())) as size_pretty,
                        current_database() as database_name
                """)).fetchone()
                
                # –†–∞–∑–º–µ—Ä—ã –≤—Å–µ—Ö —Ç–∞–±–ª–∏—Ü
                table_sizes = db.execute(text("""
                    SELECT 
                        schemaname,
                        tablename,
                        pg_total_relation_size(quote_ident(schemaname)||'.'||quote_ident(tablename)) as total_bytes,
                        pg_size_pretty(pg_total_relation_size(quote_ident(schemaname)||'.'||quote_ident(tablename))) as total_size,
                        pg_relation_size(quote_ident(schemaname)||'.'||quote_ident(tablename)) as table_bytes,
                        pg_size_pretty(pg_relation_size(quote_ident(schemaname)||'.'||quote_ident(tablename))) as table_size,
                        pg_total_relation_size(quote_ident(schemaname)||'.'||quote_ident(tablename)) - 
                        pg_relation_size(quote_ident(schemaname)||'.'||quote_ident(tablename)) as index_bytes,
                        pg_size_pretty(pg_total_relation_size(quote_ident(schemaname)||'.'||quote_ident(tablename)) - 
                        pg_relation_size(quote_ident(schemaname)||'.'||quote_ident(tablename))) as index_size
                    FROM pg_tables 
                    WHERE schemaname = 'public'
                    ORDER BY pg_total_relation_size(quote_ident(schemaname)||'.'||quote_ident(tablename)) DESC
                """)).fetchall()
                
                # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å—Ç—Ä–æ–∫ –≤ —Ç–∞–±–ª–∏—Ü–∞—Ö
                row_counts = db.execute(text("""
                    SELECT 
                        schemaname,
                        relname as tablename,
                        n_tup_ins as inserts,
                        n_tup_upd as updates,
                        n_tup_del as deletes,
                        n_live_tup as live_rows,
                        n_dead_tup as dead_rows,
                        last_vacuum,
                        last_autovacuum,
                        last_analyze,
                        last_autoanalyze
                    FROM pg_stat_user_tables
                    ORDER BY n_live_tup DESC
                """)).fetchall()
                
                # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –∏–Ω–¥–µ–∫—Å–∞—Ö
                index_sizes = db.execute(text("""
                    SELECT 
                        schemaname,
                        tablename,
                        indexname,
                        pg_size_pretty(pg_relation_size(quote_ident(schemaname)||'.'||quote_ident(indexname))) as index_size,
                        pg_relation_size(quote_ident(schemaname)||'.'||quote_ident(indexname)) as index_bytes
                    FROM pg_indexes 
                    WHERE schemaname = 'public'
                    ORDER BY pg_relation_size(quote_ident(schemaname)||'.'||quote_ident(indexname)) DESC
                """)).fetchall()
                
                # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö
                tables = []
                for table_row in table_sizes:
                    # –ò—â–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Å—Ç—Ä–æ–∫ –¥–ª—è —ç—Ç–æ–π —Ç–∞–±–ª–∏—Ü—ã
                    table_stats = next((r for r in row_counts if r.tablename == table_row.tablename), None)
                    
                    # –ò—â–µ–º –∏–Ω–¥–µ–∫—Å—ã –¥–ª—è —ç—Ç–æ–π —Ç–∞–±–ª–∏—Ü—ã
                    table_indexes = [
                        {
                            'name': idx.indexname,
                            'size': idx.index_size,
                            'bytes': idx.index_bytes
                        }
                        for idx in index_sizes if idx.tablename == table_row.tablename
                    ]
                    
                    table_info = {
                        'schema': table_row.schemaname,
                        'name': table_row.tablename,
                        'total_size': table_row.total_size,
                        'total_bytes': table_row.total_bytes,
                        'table_size': table_row.table_size,
                        'table_bytes': table_row.table_bytes,
                        'index_size': table_row.index_size,
                        'index_bytes': table_row.index_bytes,
                        'indexes': table_indexes
                    }
                    
                    if table_stats:
                        table_info.update({
                            'live_rows': table_stats.live_rows,
                            'dead_rows': table_stats.dead_rows,
                            'inserts': table_stats.inserts,
                            'updates': table_stats.updates,
                            'deletes': table_stats.deletes,
                            'last_vacuum': table_stats.last_vacuum.isoformat() if table_stats.last_vacuum else None,
                            'last_analyze': table_stats.last_analyze.isoformat() if table_stats.last_analyze else None
                        })
                    
                    tables.append(table_info)
                
                return {
                    'timestamp': datetime.utcnow().isoformat(),
                    'database': {
                        'name': db_info.database_name,
                        'size_bytes': db_info.size_bytes,
                        'size_pretty': db_info.size_pretty,
                        'size_gb': round(db_info.size_bytes / (1024**3), 2)
                    },
                    'tables': tables,
                    'total_tables': len(tables),
                    'largest_table': tables[0] if tables else None
                }
            finally:
                db.close()
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ä–∞–∑–º–µ—Ä–µ –ë–î: {e}")
            return {'error': str(e)}
    
    def get_disk_space_info(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–∏—Å–∫–æ–≤–æ–º –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ"""
        try:
            db = next(get_db())
            try:
                # –ü—É—Ç—å –∫ –¥–∞–Ω–Ω—ã–º PostgreSQL
                data_directory = db.execute(text("""
                    SELECT setting FROM pg_settings WHERE name = 'data_directory'
                """)).scalar()
                
                disk_info = {}
                
                if data_directory and os.path.exists(data_directory):
                    usage = psutil.disk_usage(data_directory)
                    disk_info = {
                        'data_directory': data_directory,
                        'total_bytes': usage.total,
                        'used_bytes': usage.used,
                        'free_bytes': usage.free,
                        'total_gb': round(usage.total / (1024**3), 2),
                        'used_gb': round(usage.used / (1024**3), 2),
                        'free_gb': round(usage.free / (1024**3), 2),
                        'used_percent': round(usage.used / usage.total * 100, 2),
                        'free_percent': round(usage.free / usage.total * 100, 2)
                    }
                else:
                    # Fallback - –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ç–µ–∫—É—â–∏–π –¥–∏—Å–∫
                    usage = psutil.disk_usage('.')
                    disk_info = {
                        'data_directory': 'unknown (using current directory)',
                        'total_bytes': usage.total,
                        'used_bytes': usage.used,
                        'free_bytes': usage.free,
                        'total_gb': round(usage.total / (1024**3), 2),
                        'used_gb': round(usage.used / (1024**3), 2),
                        'free_gb': round(usage.free / (1024**3), 2),
                        'used_percent': round(usage.used / usage.total * 100, 2),
                        'free_percent': round(usage.free / usage.total * 100, 2)
                    }
                
                return disk_info
            finally:
                db.close()
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –¥–∏—Å–∫–µ: {e}")
            return {'error': str(e)}
    
    def calculate_growth_rate(self, current_size: int) -> Optional[float]:
        """–í—ã—á–∏—Å–ª—è–µ—Ç —Å–∫–æ—Ä–æ—Å—Ç—å —Ä–æ—Å—Ç–∞ –ë–î –≤ MB/–¥–µ–Ω—å"""
        try:
            history = self.load_size_history()
            
            if len(history) < 2:
                return None
                
            # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ –¥–≤–µ –∑–∞–ø–∏—Å–∏ –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞
            prev_record = history[-2]
            current_time = datetime.utcnow()
            prev_time = datetime.fromisoformat(prev_record['timestamp'])
            
            time_diff_days = (current_time - prev_time).total_seconds() / 86400
            if time_diff_days <= 0:
                return None
                
            size_diff_mb = (current_size - prev_record['size_bytes']) / (1024**2)
            growth_rate = size_diff_mb / time_diff_days
            
            return round(growth_rate, 2)
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ —Å–∫–æ—Ä–æ—Å—Ç–∏ —Ä–æ—Å—Ç–∞: {e}")
            return None
    
    def load_size_history(self) -> List[Dict]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—é —Ä–∞–∑–º–µ—Ä–æ–≤ –ë–î"""
        try:
            if self.history_file.exists():
                with open(self.history_file, 'r') as f:
                    return json.load(f)
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏—Å—Ç–æ—Ä–∏–∏ —Ä–∞–∑–º–µ—Ä–æ–≤: {e}")
        return []
    
    def save_size_history(self, db_info: Dict) -> None:
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ç–µ–∫—É—â–∏–π —Ä–∞–∑–º–µ—Ä –≤ –∏—Å—Ç–æ—Ä–∏—é"""
        try:
            history = self.load_size_history()
            
            # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—É—é –∑–∞–ø–∏—Å—å
            history.append({
                'timestamp': datetime.utcnow().isoformat(),
                'size_bytes': db_info['database']['size_bytes'],
                'size_gb': db_info['database']['size_gb'],
                'table_count': db_info['total_tables']
            })
            
            # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 30 –¥–Ω–µ–π (–ø—Ä–∏ —á–∞—Å—Ç–æ—Ç–µ 1 —Ä–∞–∑ –≤ —á–∞—Å = 720 –∑–∞–ø–∏—Å–µ–π)
            max_records = 720
            if len(history) > max_records:
                history = history[-max_records:]
            
            with open(self.history_file, 'w') as f:
                json.dump(history, f, indent=2)
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏—Å—Ç–æ—Ä–∏–∏ —Ä–∞–∑–º–µ—Ä–æ–≤: {e}")
    
    def check_thresholds(self, db_info: Dict, disk_info: Dict) -> List[Dict]:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ—Ä–æ–≥–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∞–ª–µ—Ä—Ç—ã"""
        alerts = []
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–∞ –ë–î
        db_size_gb = db_info['database']['size_gb']
        if db_size_gb > self.thresholds['db_size_gb']:
            alerts.append({
                'type': 'database_size',
                'severity': 'warning',
                'message': f"–†–∞–∑–º–µ—Ä –ë–î –ø—Ä–µ–≤—ã—Å–∏–ª –ø–æ—Ä–æ–≥: {db_size_gb:.2f}GB > {self.thresholds['db_size_gb']}GB",
                'current_value': db_size_gb,
                'threshold': self.thresholds['db_size_gb']
            })
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–æ–≤ —Ç–∞–±–ª–∏—Ü
        for table in db_info['tables']:
            table_size_gb = table['total_bytes'] / (1024**3)
            if table_size_gb > self.thresholds['table_size_gb']:
                alerts.append({
                    'type': 'table_size',
                    'severity': 'info',
                    'message': f"–¢–∞–±–ª–∏—Ü–∞ {table['name']} –ø—Ä–µ–≤—ã—Å–∏–ª–∞ –ø–æ—Ä–æ–≥: {table_size_gb:.2f}GB > {self.thresholds['table_size_gb']}GB",
                    'table_name': table['name'],
                    'current_value': table_size_gb,
                    'threshold': self.thresholds['table_size_gb']
                })
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∏—Å–∫–æ–≤–æ–≥–æ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞
        if 'used_percent' in disk_info:
            used_percent = disk_info['used_percent'] / 100
            if used_percent > self.thresholds['disk_usage_percent']:
                alerts.append({
                    'type': 'disk_space',
                    'severity': 'critical',
                    'message': f"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –¥–∏—Å–∫–∞ –ø—Ä–µ–≤—ã—Å–∏–ª–æ –ø–æ—Ä–æ–≥: {disk_info['used_percent']:.1f}% > {self.thresholds['disk_usage_percent']*100:.1f}%",
                    'current_value': used_percent,
                    'threshold': self.thresholds['disk_usage_percent'],
                    'free_gb': disk_info['free_gb']
                })
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–∫–æ—Ä–æ—Å—Ç–∏ —Ä–æ—Å—Ç–∞
        growth_rate = self.calculate_growth_rate(db_info['database']['size_bytes'])
        if growth_rate and growth_rate > self.thresholds['growth_rate_mb_day']:
            alerts.append({
                'type': 'growth_rate',
                'severity': 'warning',
                'message': f"–°–∫–æ—Ä–æ—Å—Ç—å —Ä–æ—Å—Ç–∞ –ë–î –ø—Ä–µ–≤—ã—Å–∏–ª–∞ –ø–æ—Ä–æ–≥: {growth_rate:.2f}MB/–¥–µ–Ω—å > {self.thresholds['growth_rate_mb_day']}MB/–¥–µ–Ω—å",
                'current_value': growth_rate,
                'threshold': self.thresholds['growth_rate_mb_day']
            })
        
        return alerts
    
    def send_email_alert(self, alerts: List[Dict], db_info: Dict, disk_info: Dict) -> None:
        """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç email –∞–ª–µ—Ä—Ç"""
        if not self.email_alerts or not self.alert_emails or not MimeText:
            return
            
        try:
            # –§–æ—Ä–º–∏—Ä—É–µ–º —Ç–µ–º—É –ø–∏—Å—å–º–∞
            critical_alerts = [a for a in alerts if a.get('severity') == 'critical']
            if critical_alerts:
                subject = f"üö® –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô –ê–õ–ï–†–¢ –ë–î - ChatAI"
            else:
                subject = f"‚ö†Ô∏è –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –æ —Ä–∞–∑–º–µ—Ä–µ –ë–î - ChatAI"
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º —Ç–µ–ª–æ –ø–∏—Å—å–º–∞
            body = f"""
–û—Ç—á–µ—Ç –æ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö ChatAI
–í—Ä–µ–º—è: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

üìä –¢–ï–ö–£–©–ï–ï –°–û–°–¢–û–Ø–ù–ò–ï:
‚Ä¢ –†–∞–∑–º–µ—Ä –ë–î: {db_info['database']['size_pretty']} ({db_info['database']['size_gb']:.2f} GB)
‚Ä¢ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–∞–±–ª–∏—Ü: {db_info['total_tables']}
‚Ä¢ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –¥–∏—Å–∫–∞: {disk_info.get('used_percent', 'N/A')}%
‚Ä¢ –°–≤–æ–±–æ–¥–Ω–æ–µ –º–µ—Å—Ç–æ: {disk_info.get('free_gb', 'N/A')} GB

üö® –ê–õ–ï–†–¢–´:
"""
            
            for alert in alerts:
                severity_emoji = {
                    'critical': 'üî¥',
                    'warning': 'üü°', 
                    'info': 'üîµ'
                }.get(alert.get('severity', 'info'), 'üîµ')
                
                body += f"\n{severity_emoji} {alert['message']}"
            
            body += f"""

üìà –°–ê–ú–´–ï –ë–û–õ–¨–®–ò–ï –¢–ê–ë–õ–ò–¶–´:
"""
            for i, table in enumerate(db_info['tables'][:5], 1):
                body += f"\n{i}. {table['name']}: {table['total_size']} ({table['live_rows']:,} —Å—Ç—Ä–æ–∫)"
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º email
            msg = MimeMultipart()
            msg['From'] = os.getenv('SMTP_USER', 'noreply@chatai.com')
            msg['Subject'] = subject
            msg.attach(MimeText(body, 'plain', 'utf-8'))
            
            for email in self.alert_emails:
                if email.strip():
                    msg['To'] = email.strip()
                    
                    server = smtplib.SMTP(os.getenv('SMTP_HOST', 'localhost'), int(os.getenv('SMTP_PORT', '587')))
                    if os.getenv('SMTP_USER') and os.getenv('SMTP_PASSWORD'):
                        server.starttls()
                        server.login(os.getenv('SMTP_USER'), os.getenv('SMTP_PASSWORD'))
                    
                    server.send_message(msg)
                    server.quit()
                    
                    logger.info(f"Email –∞–ª–µ—Ä—Ç –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω –Ω–∞ {email}")
                    
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ email –∞–ª–µ—Ä—Ç–∞: {e}")
    
    def generate_full_report(self) -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç –æ —Å–æ—Å—Ç–æ—è–Ω–∏–∏ –ë–î"""
        db_info = self.get_database_size_info()
        if 'error' in db_info:
            return db_info
            
        disk_info = self.get_disk_space_info()
        growth_rate = self.calculate_growth_rate(db_info['database']['size_bytes'])
        alerts = self.check_thresholds(db_info, disk_info)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é
        self.save_size_history(db_info)
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∞–ª–µ—Ä—Ç—ã –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏
        if alerts:
            self.send_email_alert(alerts, db_info, disk_info)
            
            # –õ–æ–≥–∏—Ä—É–µ–º –∞–ª–µ—Ä—Ç—ã –≤ audit log
            for alert in alerts:
                audit_log(
                    operation='db_size_alert',
                    status='warning' if alert['severity'] != 'critical' else 'critical',
                    details=alert
                )
        
        report = {
            'timestamp': datetime.utcnow().isoformat(),
            'database_info': db_info,
            'disk_info': disk_info,
            'growth_rate_mb_per_day': growth_rate,
            'alerts': alerts,
            'thresholds': self.thresholds,
            'health_status': 'critical' if any(a['severity'] == 'critical' for a in alerts) else 
                           'warning' if alerts else 'healthy'
        }
        
        return report


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞"""
    monitor = DatabaseSizeMonitor()
    
    try:
        report = monitor.generate_full_report()
        
        # –í—ã–≤–æ–¥–∏–º –æ—Ç—á–µ—Ç
        print(json.dumps(report, indent=2, ensure_ascii=False))
        
        # –õ–æ–≥–∏—Ä—É–µ–º —É—Å–ø–µ—à–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ
        audit_log(
            operation='db_size_monitoring',
            status='success',
            details={
                'db_size_gb': report['database_info']['database']['size_gb'],
                'alerts_count': len(report['alerts']),
                'health_status': report['health_status'],
                'disk_usage_percent': report['disk_info'].get('used_percent', 0)
            }
        )
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π –∫–æ–¥ –≤—ã—Ö–æ–¥–∞
        if report['health_status'] == 'critical':
            sys.exit(2)
        elif report['health_status'] == 'warning':
            sys.exit(1)
        else:
            sys.exit(0)
            
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –ë–î: {e}")
        print(json.dumps({'error': str(e)}, indent=2))
        sys.exit(3)


if __name__ == '__main__':
    main()