# –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç: –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å –∑–∞—â–∏—Ç–æ–π –æ—Ç —Ç–æ–∫–µ–Ω–æ–≤

## üõ°Ô∏è –ß—Ç–æ —ç—Ç–æ –∏ –∑–∞—á–µ–º?

–°–∏—Å—Ç–µ–º–∞ –∑–∞—â–∏—Ç—ã –æ—Ç —Ç—Ä–∞—Ç —Ç–æ–∫–µ–Ω–æ–≤ **–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –±–ª–æ–∫–∏—Ä—É–µ—Ç** –≤—Å–µ —Ä–µ–∞–ª—å–Ω—ã–µ LLM –≤—ã–∑–æ–≤—ã –≤ —Ç–µ—Å—Ç–∞—Ö, –∑–∞–º–µ–Ω—è—è –∏—Ö –Ω–∞ —Ñ–µ–π–∫–æ–≤—ã–µ —Å –Ω—É–ª–µ–≤–æ–π —Å—Ç–æ–∏–º–æ—Å—Ç—å—é. –≠—Ç–æ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–Ω–æ –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è —Å–ª—É—á–∞–π–Ω—ã—Ö —Ç—Ä–∞—Ç –Ω–∞ OpenAI/Anthropic API –≤–æ –≤—Ä–µ–º—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ –∏ CI/CD.

## ‚ö° –ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ (30 —Å–µ–∫—É–Ω–¥)

```bash
# –ü–µ—Ä–µ–π–¥–∏—Ç–µ –≤ backend –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
cd backend

# –ó–∞–ø—É—Å—Ç–∏—Ç–µ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ —Ç–µ—Å—Ç—ã –∑–∞—â–∏—Ç—ã
python3 -m pytest tests/test_token_protection_simple.py -v

# –û–∂–∏–¥–∞–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç:
# ‚úÖ 7 passed in 0.06s
# ‚úÖ –í—ã–ø–æ–ª–Ω–µ–Ω–æ 50 AI –≤—ã–∑–æ–≤–æ–≤ —Å –ù–£–õ–ï–í–û–ô —Ç—Ä–∞—Ç–æ–π —Ç–æ–∫–µ–Ω–æ–≤
```

## üìù –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤ –∫–æ–¥–µ

### ‚úÖ –ü—Ä–∞–≤–∏–ª—å–Ω–æ (–∑–∞—â–∏—â—ë–Ω–Ω–æ):
```python
from services.llm_client import generate_ai_response

async def my_function():
    # –í —Ç–µ—Å—Ç–∞—Ö –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç FakeLLM (0 —Ç–æ–∫–µ–Ω–æ–≤)
    # –í production –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ä–µ–∞–ª—å–Ω—ã–π LLM
    response = await generate_ai_response(
        messages=[{"role": "user", "content": "Hello"}],
        dialog_id=123
    )
    
    # –í —Ç–µ—Å—Ç–∞—Ö: response["metadata"]["is_fake"] == True
    # –í —Ç–µ—Å—Ç–∞—Ö: response["metadata"]["tokens_used"] == 0
    return response["content"]
```

### ‚ùå –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ (–æ–ø–∞—Å–Ω–æ):
```python
import openai  # –ù–ï –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –Ω–∞–ø—Ä—è–º—É—é!

# –≠—Ç–æ –º–æ–∂–µ—Ç –ø–æ—Ç—Ä–∞—Ç–∏—Ç—å —Ç–æ–∫–µ–Ω—ã –≤ —Ç–µ—Å—Ç–∞—Ö!
response = openai.ChatCompletion.create(
    model="gpt-4",
    messages=[{"role": "user", "content": "Hello"}]
)
```

## üß™ –ù–∞–ø–∏—Å–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤

### –®–∞–±–ª–æ–Ω –±–µ–∑–æ–ø–∞—Å–Ω–æ–≥–æ —Ç–µ—Å—Ç–∞:
```python
import pytest
from services.llm_client import generate_ai_response

class TestMyFeature:
    @pytest.mark.asyncio
    async def test_my_ai_feature(self):
        """–¢–µ—Å—Ç —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –∑–∞—â–∏—Ç–æ–π –æ—Ç —Ç—Ä–∞—Ç —Ç–æ–∫–µ–Ω–æ–≤"""
        
        response = await generate_ai_response(
            messages=[{"role": "user", "content": "test message"}],
            dialog_id=456
        )
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ç–æ–∫–µ–Ω—ã –ù–ï –ø–æ—Ç—Ä–∞—á–µ–Ω—ã
        assert response["metadata"]["is_fake"] == True
        assert response["metadata"]["tokens_used"] == 0
        assert response["metadata"]["cost"] == 0.0
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±–∏–∑–Ω–µ—Å-–ª–æ–≥–∏–∫—É
        assert "test message" in response["content"]
```

## üîç –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –ø—Ä–æ–±–ª–µ–º

### –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏:
```python
from services.ws_config import get_config

config = get_config()
print("–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è LLM:", config['llm'])

# –î–æ–ª–∂–Ω–æ –ø–æ–∫–∞–∑–∞—Ç—å:
# {
#   'environment': 'test',
#   'is_test_env': True,
#   'provider': 'fake', 
#   'block_external_io': True
# }
```

### –Ø–≤–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞—â–∏—Ç—ã:
```python
from conftest import ensure_no_tokens_spent

# –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —á—Ç–æ –∑–∞—â–∏—Ç–∞ –∞–∫—Ç–∏–≤–Ω–∞
ensure_no_tokens_spent()  # –ù–µ –≤—ã–±—Ä–∞—Å—ã–≤–∞–µ—Ç –∏—Å–∫–ª—é—á–µ–Ω–∏–µ –µ—Å–ª–∏ –≤—Å—ë –û–ö
```

## üö® –ß—Ç–æ –¥–µ–ª–∞—Ç—å –µ—Å–ª–∏ —Ç–µ—Å—Ç—ã –ø–∞–¥–∞—é—Ç?

### –û—à–∏–±–∫–∞: "External IO blocked"
**–≠—Ç–æ —Ö–æ—Ä–æ—à–æ!** –°–∏—Å—Ç–µ–º–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç –∏ –±–ª–æ–∫–∏—Ä—É–µ—Ç –æ–ø–∞—Å–Ω—ã–µ –≤—ã–∑–æ–≤—ã.

–ü—Ä–æ–≤–µ—Ä—å—Ç–µ:
1. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç–µ –ª–∏ –≤—ã `generate_ai_response()` –≤–º–µ—Å—Ç–æ –ø—Ä—è–º—ã—Ö LLM –≤—ã–∑–æ–≤–æ–≤?
2. –ü—Ä–∞–≤–∏–ª—å–Ω–æ –ª–∏ –∏–º–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç–µ –º–æ–¥—É–ª–∏ –ø–æ—Å–ª–µ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è?

### –û—à–∏–±–∫–∞: "Expected FakeLLM, got OpenAILLM"  
**–≠—Ç–æ –æ–ø–∞—Å–Ω–æ!** –í–æ–∑–º–æ–∂–Ω–∞ —Ç—Ä–∞—Ç–∞ —Ç–æ–∫–µ–Ω–æ–≤.

–†–µ—à–µ–Ω–∏–µ:
```bash
# –ü–µ—Ä–µ—É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
export ENVIRONMENT=test
export LLM_PROVIDER=fake
export BLOCK_EXTERNAL_IO=true

# –ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç–µ —Ç–µ—Å—Ç—ã
pytest tests/test_token_protection_simple.py -v
```

### –û—à–∏–±–∫–∞: "tokens_used > 0"
**–ö–†–ò–¢–ò–ß–ù–û!** –ù–µ–º–µ–¥–ª–µ–Ω–Ω–æ –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ —Ç–µ—Å—Ç—ã!

–î–µ–π—Å—Ç–≤–∏—è:
1. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏ –Ω–∞ –ø—Ä–µ–¥–º–µ—Ç —Ä–µ–∞–ª—å–Ω—ã—Ö LLM –≤—ã–∑–æ–≤–æ–≤
2. –ó–∞–ø—É—Å—Ç–∏—Ç–µ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫—É: `ensure_no_tokens_spent()`
3. –£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ `conftest.py` –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ

## üéØ –ö–ª—é—á–µ–≤—ã–µ –ø—Ä–∏–Ω—Ü–∏–ø—ã

### ‚úÖ –í—Å–µ–≥–¥–∞:
- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ `generate_ai_response()` –¥–ª—è AI –≤—ã–∑–æ–≤–æ–≤
- –ü—Ä–æ–≤–µ—Ä—è–π—Ç–µ `is_fake: true` –≤ —Ç–µ—Å—Ç–∞—Ö
- –ó–∞–ø—É—Å–∫–∞–π—Ç–µ —Ç–µ—Å—Ç—ã –∑–∞—â–∏—Ç—ã –ø–µ—Ä–µ–¥ –∫–æ–º–º–∏—Ç–æ–º
- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ñ–∏–∫—Å—Ç—É—Ä—ã –∏–∑ `conftest.py`

### ‚ùå –ù–∏–∫–æ–≥–¥–∞:
- –ù–ï –∏–º–ø–æ—Ä—Ç–∏—Ä—É–π—Ç–µ OpenAI/Anthropic –Ω–∞–ø—Ä—è–º—É—é –≤ —Ç–µ—Å—Ç–∞—Ö
- –ù–ï —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–π—Ç–µ `BLOCK_EXTERNAL_IO=false` –≤ CI/CD
- –ù–ï –∏–≥–Ω–æ—Ä–∏—Ä—É–π—Ç–µ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è –æ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö —Ç—Ä–∞—Ç–∞—Ö
- –ù–ï –∫–æ–º–º–∏—Ç—å—Ç–µ –∫–æ–¥ –±–µ–∑ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∑–∞—â–∏—Ç—ã

## üöÄ –ö–æ–º–∞–Ω–¥—ã –¥–ª—è –µ–∂–µ–¥–Ω–µ–≤–Ω–æ–π —Ä–∞–±–æ—Ç—ã

```bash
# –ü–µ—Ä–µ–¥ –∫–æ–º–º–∏—Ç–æ–º (–±—ã—Å—Ç—Ä–æ, 6 —Å–µ–∫):
pytest tests/test_token_protection_simple.py -v

# –ü—Ä–∏ –±–æ–ª—å—à–∏—Ö –∏–∑–º–µ–Ω–µ–Ω–∏—è—Ö (–ø–æ–ª–Ω–æ, 10 —Å–µ–∫):
pytest tests/test_token_protection*.py -v

# –ü—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏—è—Ö WebSocket (30 —Å–µ–∫):
pytest tests/test_websocket_critical_fixes.py -v

# –ü–æ–ª–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å–∏—Å—Ç–µ–º—ã (60+ —Å–µ–∫):
pytest tests/ -v
```

## üìö –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è

- **–ü–æ–ª–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è**: [token-protection.md](./token-protection.md)
- **–°—Ç—Ä–∞—Ç–µ–≥–∏–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è**: [test-strategies.md](./test-strategies.md) 
- **–û–±—â–∏–π –æ–±–∑–æ—Ä —Ç–µ—Å—Ç–æ–≤**: [README.md](./README.md)
- **–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è**: `backend/services/ws_config.py`
- **LLM –∫–ª–∏–µ–Ω—Ç—ã**: `backend/services/llm_client.py`

## ‚ö° TL;DR

1. **–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ** `generate_ai_response()` –¥–ª—è AI –≤—ã–∑–æ–≤–æ–≤
2. **–ü—Ä–æ–≤–µ—Ä—è–π—Ç–µ** `response["metadata"]["is_fake"] == True` –≤ —Ç–µ—Å—Ç–∞—Ö  
3. **–ó–∞–ø—É—Å–∫–∞–π—Ç–µ** `pytest tests/test_token_protection_simple.py -v` –ø–µ—Ä–µ–¥ –∫–æ–º–º–∏—Ç–æ–º
4. **–ù–ï –∏–º–ø–æ—Ä—Ç–∏—Ä—É–π—Ç–µ** OpenAI/Anthropic –Ω–∞–ø—Ä—è–º—É—é –≤ —Ç–µ—Å—Ç–∞—Ö

**üõ°Ô∏è –†–µ–∑—É–ª—å—Ç–∞—Ç**: 0 —Ç–æ–∫–µ–Ω–æ–≤ –ø–æ—Ç—Ä–∞—á–µ–Ω–æ –≤ —Ç–µ—Å—Ç–∞—Ö, 100% –∑–∞—â–∏—Ç–∞, –±—ã—Å—Ç—Ä–∞—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞!

---

**üìÖ –°–æ–∑–¥–∞–Ω–æ**: 2025-09-06  
**üîÑ –ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ**: 2025-09-06  
**‚úÖ –°—Ç–∞—Ç—É—Å**: –ü–æ–ª–Ω–æ—Å—Ç—å—é –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–æ –∏ —Ä–∞–±–æ—Ç–∞–µ—Ç