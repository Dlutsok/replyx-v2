#!/usr/bin/env python3
"""
–ö–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏—è –º–∏–≥—Ä–∞—Ü–∏–π Alembic –¥–ª—è ReplyX
–°–æ–∑–¥–∞–µ—Ç —á–∏—Å—Ç—É—é —Å—Ö–µ–º—É –∏ –Ω–æ–≤—ã–µ –º–∏–≥—Ä–∞—Ü–∏–∏ –±–µ–∑ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–≥–æ –¥–æ–ª–≥–∞
"""

import os
import sys
import shutil
import subprocess
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any
import argparse

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ backend –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞ –º–æ–¥–µ–ª–µ–π
sys.path.append(str(Path(__file__).parent.parent.parent))

class MigrationConsolidator:
    def __init__(self, project_root: Path):
        self.project_root = project_root
        self.backend_dir = project_root
        self.alembic_dir = self.backend_dir / "alembic"
        self.versions_dir = self.alembic_dir / "versions"
        self.backup_dir = self.backend_dir / "backups" / f"migrations_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
    def create_database_backup(self, db_url: str = None) -> bool:
        """–°–æ–∑–¥–∞–µ—Ç –ø–æ–ª–Ω—ã–π –±—ç–∫–∞–ø –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
        print("üîÑ –°–æ–∑–¥–∞–Ω–∏–µ –±—ç–∫–∞–ø–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö...")
        
        try:
            # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è –±—ç–∫–∞–ø–æ–≤
            self.backup_dir.mkdir(parents=True, exist_ok=True)
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ë–î
            if not db_url:
                # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–ª–∏ –∫–æ–Ω—Ñ–∏–≥–∞
                try:
                    from core.app_config import DATABASE_URL
                    db_url = DATABASE_URL
                except ImportError:
                    db_url = os.environ.get('DATABASE_URL', 'postgresql://user:pass@localhost/chatai_db')
            
            # –°–æ–∑–¥–∞–µ–º –ø–æ–ª–Ω—ã–π –¥–∞–º–ø —Å—Ö–µ–º—ã –∏ –¥–∞–Ω–Ω—ã—Ö
            backup_file = self.backup_dir / "full_database_backup.sql"
            
            cmd = [
                'pg_dump',
                db_url,
                '--verbose',
                '--no-password',
                '--format=plain',
                '--file', str(backup_file)
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            if result.returncode != 0:
                print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –±—ç–∫–∞–ø–∞: {result.stderr}")
                return False
            
            # –°–æ–∑–¥–∞–µ–º —Ç–∞–∫–∂–µ –¥–∞–º–ø —Ç–æ–ª—å–∫–æ —Å—Ö–µ–º—ã
            schema_file = self.backup_dir / "schema_only_backup.sql"
            cmd_schema = [
                'pg_dump',
                db_url,
                '--schema-only',
                '--verbose',
                '--no-password',
                '--format=plain',
                '--file', str(schema_file)
            ]
            
            subprocess.run(cmd_schema, capture_output=True, text=True)
            
            print(f"‚úÖ –ë—ç–∫–∞–ø —Å–æ–∑–¥–∞–Ω: {backup_file}")
            print(f"‚úÖ –°—Ö–µ–º–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {schema_file}")
            return True
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –±—ç–∫–∞–ø–∞: {e}")
            return False
    
    def backup_current_migrations(self) -> bool:
        """–°–æ–∑–¥–∞–µ—Ç —Ä–µ–∑–µ—Ä–≤–Ω—É—é –∫–æ–ø–∏—é —Ç–µ–∫—É—â–∏—Ö –º–∏–≥—Ä–∞—Ü–∏–π"""
        print("üîÑ –°–æ–∑–¥–∞–Ω–∏–µ –±—ç–∫–∞–ø–∞ –º–∏–≥—Ä–∞—Ü–∏–π...")
        
        try:
            migrations_backup = self.backup_dir / "alembic_versions"
            
            if self.versions_dir.exists():
                shutil.copytree(self.versions_dir, migrations_backup)
                
                # –ö–æ–ø–∏—Ä—É–µ–º —Ç–∞–∫–∂–µ alembic.ini –∏ env.py
                shutil.copy2(self.backend_dir / "alembic.ini", self.backup_dir)
                shutil.copy2(self.alembic_dir / "env.py", self.backup_dir)
                
                print(f"‚úÖ –ú–∏–≥—Ä–∞—Ü–∏–∏ —Å–∫–æ–ø–∏—Ä–æ–≤–∞–Ω—ã –≤: {migrations_backup}")
                return True
            else:
                print("‚ùå –ü–∞–ø–∫–∞ —Å –º–∏–≥—Ä–∞—Ü–∏—è–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
                return False
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –±—ç–∫–∞–ø–∞ –º–∏–≥—Ä–∞—Ü–∏–π: {e}")
            return False
    
    def analyze_current_schema(self) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç–µ–∫—É—â—É—é —Å—Ö–µ–º—É –ë–î"""
        print("üîÑ –ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—É—â–µ–π —Å—Ö–µ–º—ã...")
        
        try:
            from database import models
            from database.connection import Base, engine
            
            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —Ç–∞–±–ª–∏—Ü—ã –∏–∑ –º–æ–¥–µ–ª–µ–π
            tables = []
            for name, obj in models.__dict__.items():
                if hasattr(obj, '__tablename__') and hasattr(obj, '__table__'):
                    table_info = {
                        'name': obj.__tablename__,
                        'model_class': name,
                        'columns': [],
                        'indexes': [],
                        'constraints': []
                    }
                    
                    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–ª–æ–Ω–∫–∏
                    for column in obj.__table__.columns:
                        table_info['columns'].append({
                            'name': column.name,
                            'type': str(column.type),
                            'nullable': column.nullable,
                            'primary_key': column.primary_key,
                            'foreign_keys': [str(fk) for fk in column.foreign_keys],
                            'default': str(column.default) if column.default else None
                        })
                    
                    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∏–Ω–¥–µ–∫—Å—ã
                    for index in obj.__table__.indexes:
                        table_info['indexes'].append({
                            'name': index.name,
                            'columns': [col.name for col in index.columns],
                            'unique': index.unique
                        })
                    
                    tables.append(table_info)
            
            schema_info = {
                'total_tables': len(tables),
                'tables': tables,
                'analysis_date': datetime.now().isoformat()
            }
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞–Ω–∞–ª–∏–∑ —Å—Ö–µ–º—ã
            import json
            schema_file = self.backup_dir / "current_schema_analysis.json"
            with open(schema_file, 'w', encoding='utf-8') as f:
                json.dump(schema_info, f, indent=2, ensure_ascii=False)
            
            print(f"‚úÖ –°—Ö–µ–º–∞ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞: {len(tables)} —Ç–∞–±–ª–∏—Ü")
            return schema_info
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Å—Ö–µ–º—ã: {e}")
            return {}
    
    def generate_consolidated_migration(self, description: str = "Consolidated base schema") -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫–æ–Ω—Å–æ–ª–∏–¥–∏—Ä–æ–≤–∞–Ω–Ω—É—é –º–∏–≥—Ä–∞—Ü–∏—é"""
        print("üîÑ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–Ω—Å–æ–ª–∏–¥–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –º–∏–≥—Ä–∞—Ü–∏–∏...")
        
        try:
            # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –≤ –ø–∞–ø–∫—É backend
            original_cwd = os.getcwd()
            os.chdir(self.backend_dir)
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –Ω–æ–≤—É—é –º–∏–≥—Ä–∞—Ü–∏—é –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—É—â–∏—Ö –º–æ–¥–µ–ª–µ–π
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            
            cmd = [
                'alembic', 'revision', 
                '--autogenerate',
                '-m', f"{timestamp}_{description.replace(' ', '_').lower()}"
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            if result.returncode != 0:
                print(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –º–∏–≥—Ä–∞—Ü–∏–∏: {result.stderr}")
                return ""
            
            # –ò—â–µ–º —Å–æ–∑–¥–∞–Ω–Ω—ã–π —Ñ–∞–π–ª –º–∏–≥—Ä–∞—Ü–∏–∏
            migration_files = list(self.versions_dir.glob(f"*{timestamp}*.py"))
            
            if migration_files:
                new_migration = migration_files[0]
                print(f"‚úÖ –°–æ–∑–¥–∞–Ω–∞ –∫–æ–Ω—Å–æ–ª–∏–¥–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–∏–≥—Ä–∞—Ü–∏—è: {new_migration.name}")
                return str(new_migration)
            else:
                print("‚ùå –§–∞–π–ª –º–∏–≥—Ä–∞—Ü–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω")
                return ""
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –º–∏–≥—Ä–∞—Ü–∏–∏: {e}")
            return ""
        finally:
            os.chdir(original_cwd)
    
    def create_clean_migration_structure(self) -> bool:
        """–°–æ–∑–¥–∞–µ—Ç —á–∏—Å—Ç—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –º–∏–≥—Ä–∞—Ü–∏–π"""
        print("üîÑ –°–æ–∑–¥–∞–Ω–∏–µ —á–∏—Å—Ç–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –º–∏–≥—Ä–∞—Ü–∏–π...")
        
        try:
            # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é –ø–∞–ø–∫—É –¥–ª—è —á–∏—Å—Ç—ã—Ö –º–∏–≥—Ä–∞—Ü–∏–π
            clean_versions_dir = self.alembic_dir / "versions_clean"
            clean_versions_dir.mkdir(exist_ok=True)
            
            # –°–æ–∑–¥–∞–µ–º –±–∞–∑–æ–≤—É—é –º–∏–≥—Ä–∞—Ü–∏—é
            base_migration_content = '''"""Base schema for ReplyX

Revision ID: {revision_id}
Revises: 
Create Date: {create_date}

"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers
revision = '{revision_id}'
down_revision = None
branch_labels = None
depends_on = None

def upgrade() -> None:
    # –≠—Ç–∞ –º–∏–≥—Ä–∞—Ü–∏—è –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –ø—É—Å—Ç–æ–π, —Ç–∞–∫ –∫–∞–∫ —Å—Ö–µ–º–∞ —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
    # –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ --sql –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ä–µ–∞–ª—å–Ω–æ–≥–æ SQL –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
    pass

def downgrade() -> None:
    # –û—Ç–∫–∞—Ç –∫ –ø—É—Å—Ç–æ–π —Å—Ö–µ–º–µ
    pass
'''
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º ID –¥–ª—è –±–∞–∑–æ–≤–æ–π –º–∏–≥—Ä–∞—Ü–∏–∏
            import secrets
            revision_id = secrets.token_hex(6)
            create_date = datetime.now()
            
            base_migration = base_migration_content.format(
                revision_id=revision_id,
                create_date=create_date.strftime('%Y-%m-%d %H:%M:%S.%f')
            )
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –±–∞–∑–æ–≤—É—é –º–∏–≥—Ä–∞—Ü–∏—é
            base_file = clean_versions_dir / f"{revision_id}_base_schema.py"
            with open(base_file, 'w', encoding='utf-8') as f:
                f.write(base_migration)
            
            print(f"‚úÖ –°–æ–∑–¥–∞–Ω–∞ –±–∞–∑–æ–≤–∞—è –º–∏–≥—Ä–∞—Ü–∏—è: {base_file.name}")
            
            # –°–æ–∑–¥–∞–µ–º –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—é –ø–æ –º–∏–≥—Ä–∞—Ü–∏–∏ –Ω–∞ –Ω–æ–≤—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É
            migration_plan = f"""
# –ü–õ–ê–ù –ú–ò–ì–†–ê–¶–ò–ò –ù–ê –ù–û–í–£–Æ –°–¢–†–£–ö–¢–£–†–£

## –®–∞–≥ 1: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞
1. –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –≤—Å–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
2. –°–æ–∑–¥–∞—Ç—å –ø–æ–ª–Ω—ã–π –±—ç–∫–∞–ø –ë–î (—É–∂–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ)
3. –£–±–µ–¥–∏—Ç—å—Å—è –≤ –Ω–∞–ª–∏—á–∏–∏ –æ—Ç–∫–∞—Ç–∞

## –®–∞–≥ 2: –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏ –º–∏–≥—Ä–∞—Ü–∏–π
```bash
# –í –ø–∞–ø–∫–µ backend
alembic stamp {revision_id}
```

## –®–∞–≥ 3: –ó–∞–º–µ–Ω–∞ –º–∏–≥—Ä–∞—Ü–∏–π
```bash
# –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞—Ç—å —Å—Ç–∞—Ä—ã–µ –º–∏–≥—Ä–∞—Ü–∏–∏
mv alembic/versions alembic/versions_old

# –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞—Ç—å –Ω–æ–≤—ã–µ –º–∏–≥—Ä–∞—Ü–∏–∏
mv alembic/versions_clean alembic/versions
```

## –®–∞–≥ 4: –ü—Ä–æ–≤–µ—Ä–∫–∞
```bash
# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Ç–µ–∫—É—â—É—é –≤–µ—Ä—Å–∏—é
alembic current

# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —á—Ç–æ –Ω–µ—Ç –∏–∑–º–µ–Ω–µ–Ω–∏–π 
alembic check
```

## –®–∞–≥ 5: –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
1. –ó–∞–ø—É—Å—Ç–∏—Ç—å –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
2. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –æ—Å–Ω–æ–≤–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏
3. –°–æ–∑–¥–∞—Ç—å —Ç–µ—Å—Ç–æ–≤—É—é –º–∏–≥—Ä–∞—Ü–∏—é –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏

## –û—Ç–∫–∞—Ç (–µ—Å–ª–∏ —á—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫)
```bash
# –í–µ—Ä–Ω—É—Ç—å —Å—Ç–∞—Ä—ã–µ –º–∏–≥—Ä–∞—Ü–∏–∏
rm -rf alembic/versions
mv alembic/versions_old alembic/versions

# –í–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –ë–î –∏–∑ –±—ç–∫–∞–ø–∞
psql -d chatai_db -f {self.backup_dir}/full_database_backup.sql
```
"""
            
            with open(self.backup_dir / "migration_plan.md", 'w', encoding='utf-8') as f:
                f.write(migration_plan)
            
            print(f"‚úÖ –ü–ª–∞–Ω –º–∏–≥—Ä–∞—Ü–∏–∏ —Å–æ–∑–¥–∞–Ω: {self.backup_dir}/migration_plan.md")
            return True
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —á–∏—Å—Ç–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã: {e}")
            return False
    
    def validate_consolidation(self) -> bool:
        """–í–∞–ª–∏–¥–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∫–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏–∏"""
        print("üîÑ –í–∞–ª–∏–¥–∞—Ü–∏—è –∫–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏–∏...")
        
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –Ω–æ–≤—ã–µ –º–∏–≥—Ä–∞—Ü–∏–∏ —Ä–∞–±–æ—Ç–∞—é—Ç
            original_cwd = os.getcwd()
            os.chdir(self.backend_dir)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–∏–Ω—Ç–∞–∫—Å–∏—Å –∞–ª–µ–º–±–∏–∫–∞
            cmd = ['alembic', 'check']
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            if result.returncode == 0:
                print("‚úÖ –°–∏–Ω—Ç–∞–∫—Å–∏—Å –º–∏–≥—Ä–∞—Ü–∏–π –∫–æ—Ä—Ä–µ–∫—Ç–µ–Ω")
            else:
                print(f"‚ùå –ü—Ä–æ–±–ª–µ–º—ã —Å —Å–∏–Ω—Ç–∞–∫—Å–∏—Å–æ–º: {result.stderr}")
                return False
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –º–æ–∂–Ω–æ –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –Ω–æ–≤—ã–µ –º–∏–≥—Ä–∞—Ü–∏–∏  
            cmd = ['alembic', 'revision', '--autogenerate', '-m', 'test_migration', '--sql']
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            if "No changes" in result.stdout or result.returncode == 0:
                print("‚úÖ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –Ω–æ–≤—ã—Ö –º–∏–≥—Ä–∞—Ü–∏–π —Ä–∞–±–æ—Ç–∞–µ—Ç")
            else:
                print(f"‚ùå –ü—Ä–æ–±–ª–µ–º—ã —Å –≥–µ–Ω–µ—Ä–∞—Ü–∏–µ–π: {result.stderr}")
                return False
            
            return True
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {e}")
            return False
        finally:
            os.chdir(original_cwd)
    
    def create_monitoring_queries(self):
        """–°–æ–∑–¥–∞–µ—Ç SQL –∑–∞–ø—Ä–æ—Å—ã –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –ø–æ—Å–ª–µ –∫–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏–∏"""
        
        monitoring_sql = '''-- –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø–æ—Å–ª–µ –∫–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏–∏ –º–∏–≥—Ä–∞—Ü–∏–π ReplyX

-- 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö
SELECT 
    table_name,
    n_tup_ins as inserts,
    n_tup_upd as updates, 
    n_tup_del as deletes,
    n_live_tup as live_rows,
    n_dead_tup as dead_rows,
    last_vacuum,
    last_autovacuum,
    last_analyze,
    last_autoanalyze
FROM pg_stat_user_tables
ORDER BY n_live_tup DESC;

-- 2. –°–æ—Å—Ç–æ—è–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–æ–≤ –ø–æ—Å–ª–µ –∫–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏–∏
SELECT 
    schemaname,
    tablename,
    indexname,
    idx_scan,
    idx_tup_read,
    idx_tup_fetch,
    pg_size_pretty(pg_relation_size(indexrelid)) as index_size
FROM pg_stat_user_indexes
WHERE idx_scan = 0  -- –ù–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –∏–Ω–¥–µ–∫—Å—ã
ORDER BY pg_relation_size(indexrelid) DESC;

-- 3. –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–Ω–µ—à–Ω–∏—Ö –∫–ª—é—á–µ–π
SELECT 
    tc.table_name,
    tc.constraint_name,
    tc.constraint_type,
    kcu.column_name,
    ccu.table_name AS foreign_table_name,
    ccu.column_name AS foreign_column_name
FROM information_schema.table_constraints AS tc
JOIN information_schema.key_column_usage AS kcu
    ON tc.constraint_name = kcu.constraint_name
JOIN information_schema.constraint_column_usage AS ccu
    ON ccu.constraint_name = tc.constraint_name
WHERE tc.constraint_type = 'FOREIGN KEY'
    AND tc.table_schema = 'public'
ORDER BY tc.table_name;

-- 4. –†–∞–∑–º–µ—Ä—ã —Ç–∞–±–ª–∏—Ü –ø–æ—Å–ª–µ –∫–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏–∏
SELECT 
    schemaname,
    tablename,
    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) AS total_size,
    pg_size_pretty(pg_relation_size(schemaname||'.'||tablename)) AS table_size,
    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename) - pg_relation_size(schemaname||'.'||tablename)) AS index_size
FROM pg_tables 
WHERE schemaname = 'public'
ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC;

-- 5. –ò—Å—Ç–æ—Ä–∏—è –º–∏–≥—Ä–∞—Ü–∏–π Alembic
SELECT version_num, is_head FROM alembic_version;

-- 6. –ü—Ä–æ–≤–µ—Ä–∫–∞ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π
SELECT
    tc.constraint_name,
    tc.table_name,
    kcu.column_name,
    tc.constraint_type
FROM information_schema.table_constraints tc
JOIN information_schema.key_column_usage kcu 
    ON tc.constraint_name = kcu.constraint_name
WHERE tc.constraint_type IN ('UNIQUE', 'PRIMARY KEY')
    AND tc.table_schema = 'public'
ORDER BY tc.table_name, tc.constraint_type;

-- 7. –ü—Ä–æ–≤–µ—Ä–∫–∞ NOT NULL –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π
SELECT 
    table_name,
    column_name,
    is_nullable,
    data_type
FROM information_schema.columns
WHERE table_schema = 'public'
    AND is_nullable = 'NO'
    AND column_default IS NULL
ORDER BY table_name, column_name;

-- 8. –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø–æ—Å–ª–µ –∫–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏–∏ (–≤—ã–ø–æ–ª–Ω–∏—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–∞–∑)
SELECT 
    query,
    calls,
    total_time,
    mean_time,
    max_time,
    rows
FROM pg_stat_statements
WHERE query LIKE '%SELECT%'
    AND calls > 10
ORDER BY mean_time DESC
LIMIT 20;
'''
        
        monitoring_file = self.backup_dir / "post_consolidation_monitoring.sql"
        with open(monitoring_file, 'w', encoding='utf-8') as f:
            f.write(monitoring_sql)
        
        print(f"‚úÖ –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Å–æ–∑–¥–∞–Ω: {monitoring_file}")
    
    def run_consolidation(self, db_url: str = None, skip_backup: bool = False) -> bool:
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–æ–ª–Ω—É—é –∫–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏—é –º–∏–≥—Ä–∞—Ü–∏–π"""
        print("üöÄ –ó–ê–ü–£–°–ö –ö–û–ù–°–û–õ–ò–î–ê–¶–ò–ò –ú–ò–ì–†–ê–¶–ò–ô REPLYX")
        print("=" * 60)
        
        success = True
        
        # –®–∞–≥ 1: –ë—ç–∫–∞–ø—ã
        if not skip_backup:
            if not self.create_database_backup(db_url):
                return False
            
            if not self.backup_current_migrations():
                return False
        else:
            print("‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫ —Å–æ–∑–¥–∞–Ω–∏—è –±—ç–∫–∞–ø–æ–≤ (--skip-backup)")
        
        # –®–∞–≥ 2: –ê–Ω–∞–ª–∏–∑ —Å—Ö–µ–º—ã
        schema_info = self.analyze_current_schema()
        if not schema_info:
            print("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å—Ö–µ–º—É, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º...")
        
        # –®–∞–≥ 3: –°–æ–∑–¥–∞–Ω–∏–µ —á–∏—Å—Ç–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
        if not self.create_clean_migration_structure():
            success = False
        
        # –®–∞–≥ 4: –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
        self.create_monitoring_queries()
        
        # –®–∞–≥ 5: –í–∞–ª–∏–¥–∞—Ü–∏—è (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        # if not self.validate_consolidation():
        #     print("‚ö†Ô∏è –í–∞–ª–∏–¥–∞—Ü–∏—è –Ω–µ –ø—Ä–æ—à–ª–∞, –Ω–æ –∫–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
        
        if success:
            print("\n‚úÖ –ö–û–ù–°–û–õ–ò–î–ê–¶–ò–Ø –£–°–ü–ï–®–ù–û –ó–ê–í–ï–†–®–ï–ù–ê!")
            print(f"üìÅ –í—Å–µ –±—ç–∫–∞–ø—ã –∏ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –≤: {self.backup_dir}")
            print("üìã –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:")
            print("   1. –ü—Ä–æ—á–∏—Ç–∞–π—Ç–µ migration_plan.md")
            print("   2. –û—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è")  
            print("   3. –í—ã–ø–æ–ª–Ω–∏—Ç–µ alembic stamp <revision_id>")
            print("   4. –ó–∞–º–µ–Ω–∏—Ç–µ –ø–∞–ø–∫—É versions")
            print("   5. –ó–∞–ø—É—Å—Ç–∏—Ç–µ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥")
        else:
            print("\n‚ùå –ö–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–∏–ª–∞—Å—å —Å –æ—à–∏–±–∫–∞–º–∏")
            print(f"üìÅ –õ–æ–≥–∏ –∏ –±—ç–∫–∞–ø—ã –≤: {self.backup_dir}")
        
        return success

def main():
    parser = argparse.ArgumentParser(description='–ö–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏—è –º–∏–≥—Ä–∞—Ü–∏–π ReplyX')
    parser.add_argument('--db-url', help='URL –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –±—ç–∫–∞–ø–∞')
    parser.add_argument('--skip-backup', action='store_true', 
                       help='–ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å —Å–æ–∑–¥–∞–Ω–∏–µ –±—ç–∫–∞–ø–æ–≤ (–û–ü–ê–°–ù–û!)')
    parser.add_argument('--backend-dir', 
                       default=Path(__file__).parent.parent.parent,
                       help='–ü—É—Ç—å –∫ –ø–∞–ø–∫–µ backend')
    
    args = parser.parse_args()
    
    backend_dir = Path(args.backend_dir).resolve()
    
    if not backend_dir.exists():
        print(f"‚ùå –ü–∞–ø–∫–∞ backend –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {backend_dir}")
        return 1
    
    print(f"üîß –†–∞–±–æ—Ç–∞–µ–º —Å –ø—Ä–æ–µ–∫—Ç–æ–º: {backend_dir}")
    
    consolidator = MigrationConsolidator(backend_dir)
    
    if not args.skip_backup:
        print("‚ö†Ô∏è  –í–ù–ò–ú–ê–ù–ò–ï: –≠—Ç–∞ –æ–ø–µ—Ä–∞—Ü–∏—è –∏–∑–º–µ–Ω—è–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É –º–∏–≥—Ä–∞—Ü–∏–π!")
        print("‚ö†Ô∏è  –£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ —É –≤–∞—Å –µ—Å—Ç—å –±—ç–∫–∞–ø—ã –ë–î –∏ –∫–æ–¥–∞!")
        
        confirm = input("–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å? (y/N): ")
        if confirm.lower() != 'y':
            print("‚ùå –û–ø–µ—Ä–∞—Ü–∏—è –æ—Ç–º–µ–Ω–µ–Ω–∞")
            return 0
    
    success = consolidator.run_consolidation(
        db_url=args.db_url,
        skip_backup=args.skip_backup
    )
    
    return 0 if success else 1

if __name__ == '__main__':
    exit(main())