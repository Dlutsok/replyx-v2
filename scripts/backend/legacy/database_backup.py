"""
üóÑÔ∏è –°–ò–°–¢–ï–ú–ê –ë–≠–ö–ê–ü–û–í –ë–ê–ó–´ –î–ê–ù–ù–´–• ChatAI
–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –∏ —Ä—É—á–Ω—ã–µ –±—ç–∫–∞–ø—ã —Å —Ä–æ—Ç–∞—Ü–∏–µ–π –∏ —Å–∂–∞—Ç–∏–µ–º
"""

import os
import subprocess
import gzip
import shutil
import logging
from datetime import datetime, timedelta
from pathlib import Path
from typing import List, Dict, Optional
import json
import boto3
from botocore.exceptions import ClientError

logger = logging.getLogger(__name__)

class DatabaseBackup:
    """–°–∏—Å—Ç–µ–º–∞ –±—ç–∫–∞–ø–æ–≤ PostgreSQL —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –∏ –æ–±–ª–∞—á–Ω–æ–≥–æ —Ö—Ä–∞–Ω–µ–Ω–∏—è"""
    
    def __init__(self):
        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
        self.db_host = os.getenv('DB_HOST', 'localhost')
        self.db_port = os.getenv('DB_PORT', '5432')
        self.db_name = os.getenv('DB_NAME', 'chat_ai')
        self.db_user = os.getenv('DB_USER', 'dan')
        self.db_password = os.getenv('DB_PASSWORD', '')
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –±—ç–∫–∞–ø–æ–≤
        self.backup_dir = Path(os.getenv('BACKUP_DIR', './data/backups'))
        self.max_local_backups = int(os.getenv('MAX_LOCAL_BACKUPS', '7'))  # 7 –¥–Ω–µ–π
        self.max_weekly_backups = int(os.getenv('MAX_WEEKLY_BACKUPS', '4'))  # 4 –Ω–µ–¥–µ–ª–∏
        self.max_monthly_backups = int(os.getenv('MAX_MONTHLY_BACKUPS', '12'))  # 12 –º–µ—Å—è—Ü–µ–≤
        
        # S3 –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        self.s3_enabled = os.getenv('S3_BACKUP_ENABLED', 'false').lower() == 'true'
        self.s3_bucket = os.getenv('S3_BACKUP_BUCKET')
        self.s3_region = os.getenv('S3_BACKUP_REGION', 'us-east-1')
        self.aws_access_key = os.getenv('AWS_ACCESS_KEY_ID')
        self.aws_secret_key = os.getenv('AWS_SECRET_ACCESS_KEY')
        
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        self.backup_dir.mkdir(parents=True, exist_ok=True)
        (self.backup_dir / 'daily').mkdir(exist_ok=True)
        (self.backup_dir / 'weekly').mkdir(exist_ok=True)
        (self.backup_dir / 'monthly').mkdir(exist_ok=True)
        
        # S3 –∫–ª–∏–µ–Ω—Ç
        self.s3_client = None
        if self.s3_enabled and self.s3_bucket:
            try:
                self.s3_client = boto3.client(
                    's3',
                    region_name=self.s3_region,
                    aws_access_key_id=self.aws_access_key,
                    aws_secret_access_key=self.aws_secret_key
                )
                logger.info(f"S3 –±—ç–∫–∞–ø—ã –≤–∫–ª—é—á–µ–Ω—ã: {self.s3_bucket}")
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ S3: {e}")
                self.s3_enabled = False
    
    def create_backup(self, backup_type: str = 'daily') -> Optional[Dict]:
        """–°–æ–∑–¥–∞–Ω–∏–µ –±—ç–∫–∞–ø–∞ –ë–î"""
        try:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            backup_filename = f"chatai_backup_{backup_type}_{timestamp}.sql"
            backup_path = self.backup_dir / backup_type / backup_filename
            
            logger.info(f"–°–æ–∑–¥–∞–Ω–∏–µ {backup_type} –±—ç–∫–∞–ø–∞: {backup_filename}")
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–º–∞–Ω–¥—É pg_dump
            cmd = [
                'pg_dump',
                '--host', self.db_host,
                '--port', self.db_port,
                '--username', self.db_user,
                '--dbname', self.db_name,
                '--no-password',  # –ò—Å–ø–æ–ª—å–∑—É–µ–º .pgpass –∏–ª–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
                '--verbose',
                '--clean',        # –î–æ–±–∞–≤–ª—è–µ–º DROP –∫–æ–º–∞–Ω–¥—ã
                '--if-exists',    # IF EXISTS –¥–ª—è DROP
                '--create',       # –°–æ–∑–¥–∞–Ω–∏–µ –ë–î
                '--format=plain', # SQL —Ñ–æ—Ä–º–∞—Ç
                '--file', str(backup_path)
            ]
            
            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è –ø–∞—Ä–æ–ª—è
            env = os.environ.copy()
            if self.db_password:
                env['PGPASSWORD'] = self.db_password
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º –±—ç–∫–∞–ø
            result = subprocess.run(
                cmd,
                env=env,
                capture_output=True,
                text=True,
                timeout=3600  # 1 —á–∞—Å –º–∞–∫—Å–∏–º—É–º
            )
            
            if result.returncode != 0:
                logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –±—ç–∫–∞–ø–∞: {result.stderr}")
                return None
            
            # –ü–æ–ª—É—á–∞–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
            backup_size = backup_path.stat().st_size
            
            # –°–∂–∏–º–∞–µ–º –±—ç–∫–∞–ø
            compressed_path = backup_path.with_suffix('.sql.gz')
            with open(backup_path, 'rb') as f_in:
                with gzip.open(compressed_path, 'wb') as f_out:
                    shutil.copyfileobj(f_in, f_out)
            
            # –£–¥–∞–ª—è–µ–º –Ω–µ—Å–∂–∞—Ç—ã–π —Ñ–∞–π–ª
            backup_path.unlink()
            
            compressed_size = compressed_path.stat().st_size
            compression_ratio = (1 - compressed_size / backup_size) * 100
            
            backup_info = {
                'timestamp': timestamp,
                'type': backup_type,
                'filename': compressed_path.name,
                'path': str(compressed_path),
                'size_original': backup_size,
                'size_compressed': compressed_size,
                'compression_ratio': round(compression_ratio, 2),
                'created_at': datetime.now().isoformat()
            }
            
            logger.info(f"–ë—ç–∫–∞–ø —Å–æ–∑–¥–∞–Ω: {compressed_path.name} "
                       f"({self._format_size(compressed_size)}, "
                       f"—Å–∂–∞—Ç–∏–µ {compression_ratio:.1f}%)")
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤ S3 –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ
            if self.s3_enabled:
                self._upload_to_s3(compressed_path, backup_type)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            self._save_backup_metadata(backup_info)
            
            # –û—á–∏—â–∞–µ–º —Å—Ç–∞—Ä—ã–µ –±—ç–∫–∞–ø—ã
            self._cleanup_old_backups(backup_type)
            
            return backup_info
            
        except subprocess.TimeoutExpired:
            logger.error("–¢–∞–π–º–∞—É—Ç —Å–æ–∑–¥–∞–Ω–∏—è –±—ç–∫–∞–ø–∞ (> 1 —á–∞—Å–∞)")
            return None
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –±—ç–∫–∞–ø–∞: {e}")
            return None
    
    def restore_backup(self, backup_path: str) -> bool:
        """–í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –∏–∑ –±—ç–∫–∞–ø–∞"""
        try:
            backup_file = Path(backup_path)
            if not backup_file.exists():
                logger.error(f"–§–∞–π–ª –±—ç–∫–∞–ø–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω: {backup_path}")
                return False
            
            logger.warning(f"–í–û–°–°–¢–ê–ù–û–í–õ–ï–ù–ò–ï –ë–î –∏–∑ {backup_file.name}")
            logger.warning("–≠—Ç–æ –¥–µ–π—Å—Ç–≤–∏–µ –£–î–ê–õ–ò–¢ –≤—Å–µ —Ç–µ–∫—É—â–∏–µ –¥–∞–Ω–Ω—ã–µ!")
            
            # –í—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –¥–ª—è —Ä–∞—Å–ø–∞–∫–æ–≤–∫–∏
            if backup_file.suffix == '.gz':
                temp_sql = backup_file.with_suffix('')
                with gzip.open(backup_file, 'rb') as f_in:
                    with open(temp_sql, 'wb') as f_out:
                        shutil.copyfileobj(f_in, f_out)
                sql_file = temp_sql
            else:
                sql_file = backup_file
            
            # –ö–æ–º–∞–Ω–¥–∞ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è
            cmd = [
                'psql',
                '--host', self.db_host,
                '--port', self.db_port,
                '--username', self.db_user,
                '--dbname', 'postgres',  # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ postgres –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ë–î
                '--file', str(sql_file)
            ]
            
            env = os.environ.copy()
            if self.db_password:
                env['PGPASSWORD'] = self.db_password
            
            result = subprocess.run(
                cmd,
                env=env,
                capture_output=True,
                text=True,
                timeout=3600
            )
            
            # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            if backup_file.suffix == '.gz' and temp_sql.exists():
                temp_sql.unlink()
            
            if result.returncode != 0:
                logger.error(f"–û—à–∏–±–∫–∞ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è: {result.stderr}")
                return False
            
            logger.info(f"–ë–î —É—Å–ø–µ—à–Ω–æ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –∏–∑ {backup_file.name}")
            return True
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –ë–î: {e}")
            return False
    
    def _upload_to_s3(self, backup_path: Path, backup_type: str):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –±—ç–∫–∞–ø–∞ –≤ S3"""
        try:
            if not self.s3_client:
                return
            
            s3_key = f"chatai-backups/{backup_type}/{backup_path.name}"
            
            self.s3_client.upload_file(
                str(backup_path),
                self.s3_bucket,
                s3_key,
                ExtraArgs={
                    'StorageClass': 'STANDARD_IA',  # –î–µ—à–µ–≤–æ–µ —Ö—Ä–∞–Ω–µ–Ω–∏–µ
                    'ServerSideEncryption': 'AES256'
                }
            )
            
            logger.info(f"–ë—ç–∫–∞–ø –∑–∞–≥—Ä—É–∂–µ–Ω –≤ S3: s3://{self.s3_bucket}/{s3_key}")
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –≤ S3: {e}")
    
    def _save_backup_metadata(self, backup_info: Dict):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –±—ç–∫–∞–ø–∞"""
        try:
            metadata_file = self.backup_dir / 'backup_metadata.json'
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            if metadata_file.exists():
                with open(metadata_file, 'r') as f:
                    metadata = json.load(f)
            else:
                metadata = {'backups': []}
            
            # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–π –±—ç–∫–∞–ø
            metadata['backups'].append(backup_info)
            
            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 100)
            metadata['backups'] = metadata['backups'][-100:]
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º
            with open(metadata_file, 'w') as f:
                json.dump(metadata, f, indent=2)
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö: {e}")
    
    def _cleanup_old_backups(self, backup_type: str):
        """–û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –±—ç–∫–∞–ø–æ–≤"""
        try:
            backup_folder = self.backup_dir / backup_type
            
            # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ –±—ç–∫–∞–ø–æ–≤
            backup_files = list(backup_folder.glob('*.sql.gz'))
            backup_files.sort(key=lambda x: x.stat().st_mtime, reverse=True)
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ª–∏–º–∏—Ç
            if backup_type == 'daily':
                limit = self.max_local_backups
            elif backup_type == 'weekly':
                limit = self.max_weekly_backups
            elif backup_type == 'monthly':
                limit = self.max_monthly_backups
            else:
                limit = 10
            
            # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ —Ñ–∞–π–ª—ã
            for old_backup in backup_files[limit:]:
                logger.info(f"–£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–∞—Ä–æ–≥–æ {backup_type} –±—ç–∫–∞–ø–∞: {old_backup.name}")
                old_backup.unlink()
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ —Å—Ç–∞—Ä—ã—Ö –±—ç–∫–∞–ø–æ–≤: {e}")
    
    def get_backup_list(self) -> List[Dict]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –±—ç–∫–∞–ø–æ–≤"""
        try:
            metadata_file = self.backup_dir / 'backup_metadata.json'
            
            if not metadata_file.exists():
                return []
            
            with open(metadata_file, 'r') as f:
                metadata = json.load(f)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–æ–≤
            valid_backups = []
            for backup in metadata.get('backups', []):
                backup_path = Path(backup['path'])
                if backup_path.exists():
                    backup['exists'] = True
                    backup['size_formatted'] = self._format_size(backup['size_compressed'])
                    valid_backups.append(backup)
                else:
                    backup['exists'] = False
            
            return sorted(valid_backups, key=lambda x: x['created_at'], reverse=True)
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ –±—ç–∫–∞–ø–æ–≤: {e}")
            return []
    
    def _format_size(self, size_bytes: int) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ —Ñ–∞–π–ª–∞"""
        if size_bytes == 0:
            return "0 B"
        
        for unit in ['B', 'KB', 'MB', 'GB']:
            if size_bytes < 1024:
                return f"{size_bytes:.1f} {unit}"
            size_bytes /= 1024
        
        return f"{size_bytes:.1f} TB"
    
    def create_scheduled_backups(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –∑–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –±—ç–∫–∞–ø–æ–≤ (–≤—ã–∑—ã–≤–∞–µ—Ç—Å—è –ø–æ cron)"""
        now = datetime.now()
        
        # –ï–∂–µ–¥–Ω–µ–≤–Ω—ã–π –±—ç–∫–∞–ø
        daily_backup = self.create_backup('daily')
        if not daily_backup:
            logger.error("–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –µ–∂–µ–¥–Ω–µ–≤–Ω–æ–≥–æ –±—ç–∫–∞–ø–∞")
            return False
        
        # –ï–∂–µ–Ω–µ–¥–µ–ª—å–Ω—ã–π –±—ç–∫–∞–ø (–≤–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ)
        if now.weekday() == 6:  # –í–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ
            weekly_backup = self.create_backup('weekly')
            if not weekly_backup:
                logger.error("–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –µ–∂–µ–Ω–µ–¥–µ–ª—å–Ω–æ–≥–æ –±—ç–∫–∞–ø–∞")
        
        # –ï–∂–µ–º–µ—Å—è—á–Ω—ã–π –±—ç–∫–∞–ø (–ø–µ—Ä–≤–æ–µ —á–∏—Å–ª–æ –º–µ—Å—è—Ü–∞)
        if now.day == 1:
            monthly_backup = self.create_backup('monthly')
            if not monthly_backup:
                logger.error("–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –µ–∂–µ–º–µ—Å—è—á–Ω–æ–≥–æ –±—ç–∫–∞–ø–∞")
        
        return True

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä
db_backup = DatabaseBackup()